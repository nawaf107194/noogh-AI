#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§  Unified Brain Hub - Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯
============================================

The supreme integration layer that connects ALL cognitive systems:
- Deep Cognition v1.2 Lite (97.5% TRANSCENDENT)
- Agent Brain (Planning & Reasoning)
- 14 Active Ministers (Government)
- Unified Cognition (Decision + Learning + Memory)

This is the CENTRAL NERVOUS SYSTEM of Noogh.

Author: Noogh AI Team
Version: 1.0.0
Date: 2025-11-10
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime
from dataclasses import dataclass, asdict

from src.core.di import Container


# Global flags will be managed by the Container and instance state

# Ensure MinisterType is available for type hints and runtime
try:
    from src.government.ministers_activation import MinisterType
except ImportError:
    from enum import Enum
    class MinisterType(str, Enum):
        EDUCATION = "education"
        TRAINING = "training"
        SECURITY = "security"
        DEVELOPMENT = "development"
        RESEARCH = "research"
        KNOWLEDGE = "knowledge"
        PRIVACY = "privacy"
        CREATIVITY = "creativity"
        ANALYSIS = "analysis"
        STRATEGY = "strategy"
        REASONING = "reasoning"
        COMMUNICATION = "communication"
        RESOURCES = "resources"
        FINANCE = "finance"




logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class BrainHubStatus:
    """Ø­Ø§Ù„Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯"""
    active: bool
    cognition_score: float
    active_ministers: int
    deep_cognition_available: bool
    agent_brain_available: bool
    government_available: bool
    unified_cognition_available: bool
    timestamp: str


@dataclass
class ProcessingResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…ÙˆØ­Ø¯Ø©"""
    status: str
    response: str
    minister_used: Optional[str]
    cognition_analysis: Optional[Dict]
    confidence: float
    processing_time_ms: float
    metadata: Dict[str, Any]


class UnifiedBrainHub:
    """
    ğŸ§  Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯ - The Supreme Integration Layer

    This is the CENTRAL NERVOUS SYSTEM that connects:
    1. Deep Cognition v1.2 Lite (Scene, Material, Confidence, Semantic)
    2. Agent Brain (Planning, Reasoning, Execution)
    3. 14 Active Ministers (Government)
    4. Unified Cognition (Decision + Learning + Memory)

    Flow:
    â”€â”€â”€â”€â”€
    User Request
        â†“
    Brain Hub (analyzes request type)
        â†“
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Route to appropriate system:             â”‚
    â”‚ â€¢ Vision task â†’ Deep Cognition (Scene)   â”‚
    â”‚ â€¢ Text analysis â†’ Semantic Intent        â”‚
    â”‚ â€¢ Decision â†’ Unified Cognition           â”‚
    â”‚ â€¢ Specialized task â†’ Delegate to Ministerâ”‚
    â”‚ â€¢ Complex planning â†’ Agent Brain         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â†“
    Synthesize Response
        â†“
    Return to User
    """

    def __init__(self, enable_gpu: bool = True):
        """
        ØªÙ‡ÙŠØ¦Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯

        Args:
            enable_gpu: ØªÙØ¹ÙŠÙ„ GPU Ù„Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ø°ÙŠÙ† ÙŠØ­ØªØ§Ø¬ÙˆÙ†Ù‡
        """
        logger.info("=" * 70)
        logger.info("ğŸ§  UNIFIED BRAIN HUB - INITIALIZATION")
        logger.info("=" * 70)

        self.enable_gpu = enable_gpu
        self.is_ready = False
        self.cognition_score = 0.0
        self.active_ministers_count = 0
        
        # Initialize subsystems via DI
        self._initialize_subsystems()

        # Statistics
        self.total_requests = 0
        self.successful_requests = 0

    def _initialize_subsystems(self):
        """Initialize and register all subsystems"""
        logger.info("ğŸ”§ Initializing subsystems...")

        # 1. Deep Cognition
        try:
            from src.vision.scene_understanding import SceneUnderstandingEngine
            from src.vision.material_analyzer import MaterialAnalyzer
            from src.reasoning.meta_confidence import MetaConfidenceCalibrator
            from src.nlp.semantic_intent_analyzer import SemanticIntentAnalyzer
            from src.integration.vision_reasoning_sync import VisionReasoningSynchronizer
            
            self.scene_understanding = SceneUnderstandingEngine()
            self.material_analyzer = MaterialAnalyzer()
            self.meta_confidence = MetaConfidenceCalibrator()
            self.semantic_intent = SemanticIntentAnalyzer()
            self.vision_reasoning_sync = VisionReasoningSynchronizer()
            
            Container.register("scene_understanding", self.scene_understanding)
            Container.register("semantic_intent", self.semantic_intent)
            
            self.has_deep_cognition = True
            self.cognition_score = 0.975
            logger.info("   âœ… Deep Cognition v1.2 Lite loaded")
        except ImportError as e:
            logger.warning(f"   âš ï¸ Deep Cognition not available: {e}")
            self.has_deep_cognition = False
            self.scene_understanding = None
            self.semantic_intent = None

        # 2. Agent Brain
        try:
            from src.agent.brain import AgentBrain
            self.agent_brain = AgentBrain()
            Container.register("agent_brain", self.agent_brain)
            self.has_agent_brain = True
            logger.info("   âœ… Agent Brain loaded")
        except ImportError as e:
            logger.warning(f"   âš ï¸ Agent Brain not available: {e}")
            self.has_agent_brain = False
            self.agent_brain = None

        # 3. Government
        try:
            from src.government.ministers_activation import MinistersActivationSystem, MinisterType
            self.ministers_system = MinistersActivationSystem(brain_hub=self)
            self.ministers_system.activate_all()
            self.active_ministers_count = len(self.ministers_system.active_ministers)
            Container.register("ministers_system", self.ministers_system)
            self.has_government = True
            logger.info(f"   âœ… Government loaded ({self.active_ministers_count} ministers)")
        except ImportError as e:
            logger.warning(f"   âš ï¸ Government system not available: {e}")
            self.has_government = False
            self.ministers_system = None
            
            # MinisterType is already handled at module level
            pass

        # 4. Unified Cognition
        try:
            from src.integration.unified_cognition import get_cognition_system
            self.unified_cognition = get_cognition_system()
            Container.register("unified_cognition", self.unified_cognition)
            self.has_unified_cognition = True
            logger.info("   âœ… Unified Cognition loaded")
        except ImportError as e:
            logger.warning(f"   âš ï¸ Unified Cognition not available: {e}")
            self.has_unified_cognition = False
            self.unified_cognition = None

        self.is_ready = True
        logger.info("âœ… Subsystems initialization complete")

    def process_request(self, request: str, context: Optional[Dict] = None) -> ProcessingResult:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ù…ÙˆØ­Ø¯ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

        This is the MAIN ENTRY POINT for all requests.

        Args:
            request: Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… (Ù†Øµ Ø£Ùˆ Ù…Ù‡Ù…Ø©)
            context: Ø³ÙŠØ§Ù‚ Ø¥Ø¶Ø§ÙÙŠ (ØµÙˆØ±ØŒ Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø¥Ù„Ø®)

        Returns:
            ProcessingResult with response and metadata
        """
        start_time = datetime.now()
        self.total_requests += 1

        logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        logger.info(f"ğŸ¯ Request #{self.total_requests}: {request[:50]}...")
        logger.info(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")

        context = context or {}

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: ANALYZE REQUEST TYPE
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        request_type = self._classify_request(request, context)
        logger.info(f"ğŸ“‹ Request Type: {request_type}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: ROUTE TO APPROPRIATE SYSTEM
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        response_text = ""
        minister_used = None
        cognition_analysis = None
        confidence = 0.0

        try:
            if request_type == "vision_analysis" and self.scene_understanding:
                # Use Deep Cognition - Scene Understanding
                result = self._handle_vision_analysis(request, context)
                response_text = result['response']
                cognition_analysis = result['analysis']
                confidence = result['confidence']

            elif request_type == "text_understanding" and self.semantic_intent:
                # Use Deep Cognition - Semantic Intent
                result = self._handle_text_understanding(request)
                response_text = result['response']
                cognition_analysis = result['analysis']
                confidence = result['confidence']

            elif request_type == "minister_task" and self.ministers_system:
                # Delegate to appropriate minister (async call handled safely)
                result = self._delegate_to_minister_sync(request, context)

                response_text = result['response']
                minister_used = result['minister']
                confidence = result['confidence']

            elif request_type == "complex_planning" and self.agent_brain:
                # Use Agent Brain for complex planning
                result = self._handle_complex_planning(request)
                response_text = result['response']
                confidence = result['confidence']

            elif request_type == "decision" and self.unified_cognition:
                # Use Unified Cognition for decisions
                result = self._handle_decision(request, context)
                response_text = result['response']
                confidence = result['confidence']

            else:
                # Fallback: basic response
                response_text = f"Understood request: {request}"
                confidence = 0.5

            self.successful_requests += 1
            status = "success"

        except Exception as e:
            logger.error(f"âŒ Error processing request: {e}")
            response_text = f"Error: {str(e)}"
            confidence = 0.0
            status = "error"

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 3: BUILD RESULT
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        processing_time = (datetime.now() - start_time).total_seconds() * 1000

        result = ProcessingResult(
            status=status,
            response=response_text,
            minister_used=minister_used,
            cognition_analysis=cognition_analysis,
            confidence=confidence,
            processing_time_ms=processing_time,
            metadata={
                "request_type": request_type,
                "timestamp": datetime.now().isoformat(),
                "cognition_score": self.cognition_score,
                "active_ministers": self.active_ministers_count
            }
        )

        logger.info(f"âœ… Request processed in {processing_time:.0f}ms")
        logger.info(f"   Confidence: {confidence:.0%}")

        return result

    def _classify_request(self, request: str, context: Dict) -> str:
        """
        ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ø·Ù„Ø¨

        Returns:
            One of: vision_analysis, text_understanding, minister_task,
                   complex_planning, decision
        """
        request_lower = request.lower()

        # Check for image/vision keywords
        if context.get('image_path') or any(word in request_lower for word in
            ['ØµÙˆØ±Ø©', 'image', 'Ù…Ø´Ù‡Ø¯', 'scene', 'visual', 'Ù…Ø§Ø¯Ø©', 'material']):
            return "vision_analysis"

        # Check for text understanding keywords
        if any(word in request_lower for word in
            ['Ù…Ø¹Ù†Ù‰', 'meaning', 'ÙÙ‡Ù…', 'understand', 'ØªØ­Ù„ÙŠÙ„ Ù†Øµ', 'analyze text']):
            return "text_understanding"

        # Check for minister-specific tasks
        minister_keywords = {
            # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ…
            'ØªØ¹Ù„ÙŠÙ…': 'education', 'Ø·Ù„Ø§Ø¨': 'students', 'Ø¯Ø±ÙˆØ³': 'lessons', 'ØªØ¹Ù„Ù…': 'learning',
            # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            'ØªØ¯Ø±ÙŠØ¨': 'training', 'Ù…Ù‡Ø§Ø±Ø§Øª': 'skills', 'ØªÙ…Ø±ÙŠÙ†': 'exercise',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø£Ù…Ù†
            'Ø£Ù…Ù†': 'security', 'Ø­Ù…Ø§ÙŠØ©': 'protection', 'Ø£Ù…Ø§Ù†': 'safety',
            # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ·ÙˆÙŠØ±
            'ØªØ·ÙˆÙŠØ±': 'development', 'ØªØ­Ø³ÙŠÙ†': 'improvement', 'ØªØ±Ù‚ÙŠØ©': 'upgrade',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ·ÙˆÙŠØ±
            'Ø¨Ø­Ø«': 'research', 'Ø£Ø¨Ø­Ø§Ø«': 'researches', 'Ø¯Ø±Ø§Ø³Ø©': 'study', 'ØªÙ‚Ù†ÙŠØ§Øª': 'technologies',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©
            'Ù…Ø¹Ø±ÙØ©': 'knowledge', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª': 'information', 'Ø¹Ù„Ù…': 'science', 'Ø­Ù‚Ø§Ø¦Ù‚': 'facts',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø®ØµÙˆØµÙŠØ©
            'Ø®ØµÙˆØµÙŠØ©': 'privacy', 'Ø³Ø±ÙŠØ©': 'confidentiality', 'Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©': 'personal data',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹
            'Ø¥Ø¨Ø¯Ø§Ø¹': 'creativity', 'Ø£ÙÙƒØ§Ø±': 'ideas', 'Ø§Ø¨ØªÙƒØ§Ø±': 'innovation', 'Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ': 'creative',
            # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
            'ØªØ­Ù„ÙŠÙ„': 'analysis', 'Ø­Ù„Ù„': 'analyze', 'ÙØ­Øµ': 'examination', 'ØªÙ‚ÙŠÙŠÙ…': 'evaluation',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
            'Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©': 'strategy', 'Ø®Ø·Ø©': 'plan', 'ØªØ®Ø·ÙŠØ·': 'planning',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„
            'Ø§Ø³ØªØ¯Ù„Ø§Ù„': 'reasoning', 'Ø§Ø³ØªÙ†ØªØ§Ø¬': 'inference', 'Ù…Ù†Ø·Ù‚': 'logic',
            # ÙˆØ²ÙŠØ± Ø§Ù„ØªÙˆØ§ØµÙ„
            'ØªÙˆØ§ØµÙ„': 'communication', 'Ø±Ø³Ø§Ù„Ø©': 'message', 'Ø§ØªØµØ§Ù„': 'contact',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
            'Ù…ÙˆØ§Ø±Ø¯': 'resources', 'Ù…ØµØ§Ø¯Ø±': 'sources', 'Ø£ØµÙˆÙ„': 'assets',
            # ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ©
            'Ù…Ø§Ù„ÙŠØ©': 'finance', 'ØªÙƒØ§Ù„ÙŠÙ': 'costs', 'Ù…ÙŠØ²Ø§Ù†ÙŠØ©': 'budget', 'Ø£Ù…ÙˆØ§Ù„': 'money'
        }
        if any(keyword in request_lower for keyword in minister_keywords.keys()):
            return "minister_task"

        # Check for complex planning
        if any(word in request_lower for word in
            ['Ø®Ø·Ø©', 'plan', 'Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'strategy', 'Ù…Ø´Ø±ÙˆØ¹', 'project']):
            return "complex_planning"

        # Default to decision
        return "decision"

    def _handle_vision_analysis(self, request: str, context: Dict) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ØªØ­Ù„ÙŠÙ„ Ø¨ØµØ±ÙŠ"""
        image_path = context.get('image_path')

        if not image_path:
            return {
                'response': "No image provided for vision analysis",
                'analysis': None,
                'confidence': 0.0
            }

        # Use Scene Understanding
        scene_analysis = self.scene_understanding.analyze_scene(image_path)

        # Use Material Analyzer if requested
        material_analysis = None
        if 'material' in request.lower() or 'Ù…Ø§Ø¯Ø©' in request:
            material_analysis = self.material_analyzer.analyze(image_path)

        response = f"Scene Analysis:\n"
        response += f"- Type: {scene_analysis.scene_context.scene_type.value}\n"
        response += f"- Lighting: {scene_analysis.scene_context.lighting_condition.value}\n"
        response += f"- Complexity: {scene_analysis.complexity_score:.0%}\n"

        if material_analysis:
            response += f"\nMaterial Analysis:\n"
            response += f"- Type: {material_analysis.material.material_type.value}\n"
            response += f"- Surface: {material_analysis.material.surface_property.value}\n"

        return {
            'response': response,
            'analysis': {
                'scene': asdict(scene_analysis),
                'material': asdict(material_analysis) if material_analysis else None
            },
            'confidence': scene_analysis.interpretability
        }

    def _handle_text_understanding(self, text: str) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙ‡Ù… Ø§Ù„Ù†ØµÙˆØµ"""
        analysis = self.semantic_intent.analyze(text)

        response = f"Text Understanding:\n"
        response += f"- Semantic: {analysis.semantic.value}\n"
        response += f"- Intent: {analysis.intent.value}\n"
        response += f"- Emotion: {analysis.emotional.tone.value} ({analysis.emotional.intensity:.0%})\n"
        response += f"- Alignment: {analysis.semantic_intent_alignment:.0%}\n"
        response += f"\nInterpretation: {analysis.interpreted_meaning}"

        return {
            'response': response,
            'analysis': asdict(analysis),
            'confidence': analysis.semantic_intent_alignment
        }

    async def _delegate_to_minister(self, request: str, context: Dict) -> Dict:
        """ØªÙÙˆÙŠØ¶ Ù…Ù‡Ù…Ø© Ù„ÙˆØ²ÙŠØ± (async version)"""
        # Determine which minister to use
        minister_type = self._select_minister(request)

        if not minister_type:
            return {
                'response': "No appropriate minister found",
                'minister': None,
                'confidence': 0.0
            }

        # Delegate task
        task = {
            'type': 'user_request',
            'request': request,
            **context
        }

        result = await self.ministers_system.delegate_task(minister_type, task)

        return {
            'response': f"Minister {result.get('minister', 'Unknown')} handled the task",
            'minister': result.get('minister'),
            'confidence': 0.9
        }

    def _delegate_to_minister_sync(self, request: str, context: Dict) -> Dict:
        """Safe synchronous wrapper for async minister delegation"""
        import asyncio
        import sys

        try:
            # Try to get the current event loop
            try:
                loop = asyncio.get_running_loop()
                # We're already in an async context - this shouldn't happen
                # but if it does, we need to handle it
                logger.warning("âš ï¸ Called sync wrapper from async context")
                # Create a task and return a placeholder
                return {
                    'response': "Minister delegation requires async context",
                    'minister': None,
                    'confidence': 0.0
                }
            except RuntimeError:
                # No running loop - this is the expected case
                pass

            # Safe to create and run a new event loop
            try:
                # Try to use existing event loop if available
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

            # Run the async function
            result = loop.run_until_complete(self._delegate_to_minister(request, context))
            return result

        except Exception as e:
            logger.error(f"âŒ Error delegating to minister: {e}", exc_info=True)
            return {
                'response': f"Minister delegation failed: {str(e)}",
                'minister': None,
                'confidence': 0.0
            }

    def _select_minister(self, request: str) -> Optional[MinisterType]:
        """Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù… Ù†Ù‚Ø§Ø·"""
        request_lower = request.lower()

        # Ù†Ø¸Ø§Ù… Ù†Ù‚Ø§Ø· Ù„ÙƒÙ„ ÙˆØ²ÙŠØ±
        minister_scores = {}

        # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ¹Ù„ÙŠÙ…
        education_keywords = ['ØªØ¹Ù„ÙŠÙ…', 'teach', 'Ø¯Ø±Ø³', 'Ø·Ù„Ø§Ø¨', 'students']
        minister_scores[MinisterType.EDUCATION] = sum(1 for word in education_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        training_keywords = ['ØªØ¯Ø±ÙŠØ¨', 'train', 'training', 'Ù…Ù‡Ø§Ø±Ø§Øª', 'skills', 'Ù†Ù…ÙˆØ°Ø¬', 'model']
        minister_scores[MinisterType.TRAINING] = sum(1 for word in training_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø£Ù…Ù†
        security_keywords = ['Ø£Ù…Ù†', 'security', 'protect', 'Ø­Ù…Ø§ÙŠØ©', 'protection', 'Ø£Ù…Ø§Ù†', 'safety', 'Ù‡Ø¬Ù…Ø§Øª', 'attacks']
        minister_scores[MinisterType.SECURITY] = sum(1 for word in security_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ·ÙˆÙŠØ±
        development_keywords = ['ØªØ·ÙˆÙŠØ±', 'develop', 'development', 'code', 'ØªØ­Ø³ÙŠÙ†', 'improvement', 'feature']
        minister_scores[MinisterType.DEVELOPMENT] = sum(1 for word in development_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ·ÙˆÙŠØ±
        research_keywords = ['Ø¨Ø­Ø«', 'research', 'Ø£Ø¨Ø­Ø§Ø«', 'researches', 'Ø¯Ø±Ø§Ø³Ø©', 'study', 'ØªÙ‚Ù†ÙŠØ§Øª', 'technologies']
        minister_scores[MinisterType.RESEARCH] = sum(1 for word in research_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ©
        knowledge_keywords = ['Ù…Ø¹Ø±ÙØ©', 'knowledge', 'Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'information', 'Ø¹Ù„Ù…', 'science', 'Ø­Ù‚Ø§Ø¦Ù‚', 'facts']
        minister_scores[MinisterType.KNOWLEDGE] = sum(1 for word in knowledge_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø®ØµÙˆØµÙŠØ©
        privacy_keywords = ['Ø®ØµÙˆØµÙŠØ©', 'privacy', 'Ø³Ø±ÙŠØ©', 'confidentiality', 'Ø¨ÙŠØ§Ù†Ø§Øª Ø´Ø®ØµÙŠØ©', 'personal data']
        minister_scores[MinisterType.PRIVACY] = sum(1 for word in privacy_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹
        creativity_keywords = ['Ø¥Ø¨Ø¯Ø§Ø¹', 'creativity', 'Ø£ÙÙƒØ§Ø±', 'ideas', 'Ø§Ø¨ØªÙƒØ§Ø±', 'innovation', 'Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ', 'creative']
        minister_scores[MinisterType.CREATIVITY] = sum(1 for word in creativity_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„
        analysis_keywords = ['Ø­Ù„Ù„ Ø£Ø¯Ø§Ø¡', 'ØªØ­Ù„ÙŠÙ„ Ø£Ø¯Ø§Ø¡', 'analyze performance', 'analysis', 'ÙØ­Øµ', 'examination', 'ØªÙ‚ÙŠÙŠÙ…', 'evaluation']
        minister_scores[MinisterType.ANALYSIS] = sum(1 for word in analysis_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©
        strategy_keywords = ['Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'strategy', 'Ø®Ø·Ø© Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'strategic plan', 'ØªØ®Ø·ÙŠØ·', 'planning']
        minister_scores[MinisterType.STRATEGY] = sum(1 for word in strategy_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„
        reasoning_keywords = ['Ø§Ø³ØªØ¯Ù„Ø§Ù„', 'reasoning', 'Ø§Ø³ØªÙ†ØªØ§Ø¬', 'inference', 'Ù…Ù†Ø·Ù‚', 'logic']
        minister_scores[MinisterType.REASONING] = sum(1 for word in reasoning_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„ØªÙˆØ§ØµÙ„
        communication_keywords = ['ØªÙˆØ§ØµÙ„', 'communication', 'Ø±Ø³Ø§Ù„Ø©', 'message', 'Ø§ØªØµØ§Ù„', 'contact']
        minister_scores[MinisterType.COMMUNICATION] = sum(1 for word in communication_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ù…ÙˆØ§Ø±Ø¯
        resources_keywords = ['Ù…ÙˆØ§Ø±Ø¯', 'resources', 'Ù…ØµØ§Ø¯Ø±', 'sources', 'Ø£ØµÙˆÙ„', 'assets']
        minister_scores[MinisterType.RESOURCES] = sum(1 for word in resources_keywords if word in request_lower)

        # ÙˆØ²ÙŠØ± Ø§Ù„Ù…Ø§Ù„ÙŠØ© (Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø§Ù„ÙŠØ©)
        finance_keywords = ['Ù…Ø§Ù„ÙŠØ©', 'finance', 'ØªÙƒØ§Ù„ÙŠÙ', 'costs', 'Ù…ÙŠØ²Ø§Ù†ÙŠØ©', 'budget', 'Ø£Ù…ÙˆØ§Ù„', 'money']
        minister_scores[MinisterType.FINANCE] = sum(1 for word in finance_keywords if word in request_lower)
        # Ø£Ø¹Ø· Ù†Ù‚Ø§Ø· Ø¥Ø¶Ø§ÙÙŠØ© Ø¥Ø°Ø§ ÙƒØ§Ù†Øª "ØªÙƒØ§Ù„ÙŠÙ Ù…Ø§Ù„ÙŠØ©" Ù…Ø¹Ø§Ù‹
        if 'ØªÙƒØ§Ù„ÙŠÙ' in request_lower and 'Ù…Ø§Ù„ÙŠØ©' in request_lower:
            minister_scores[MinisterType.FINANCE] += 2

        # Ø§Ø®ØªØ± Ø§Ù„ÙˆØ²ÙŠØ± Ø¨Ø£Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø·
        if minister_scores:
            max_score = max(minister_scores.values())
            if max_score > 0:
                # Ø¥Ø±Ø¬Ø§Ø¹ Ø§Ù„ÙˆØ²ÙŠØ± Ø§Ù„Ø£ÙˆÙ„ Ø¨Ø£Ø¹Ù„Ù‰ Ù†Ù‚Ø§Ø·
                for minister, score in minister_scores.items():
                    if score == max_score:
                        return minister

        return None

    def _handle_complex_planning(self, request: str) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ù…Ø¹Ù‚Ø¯"""
        task = self.agent_brain.analyze_task(request)

        response = f"Planning Result:\n"
        response += f"- Task Type: {task.task_type}\n"
        response += f"- Steps: {len(task.steps)}\n"

        for i, step in enumerate(task.steps[:3], 1):
            response += f"  {i}. {step['description']}\n"

        if len(task.steps) > 3:
            response += f"  ... and {len(task.steps) - 3} more steps\n"

        return {
            'response': response,
            'confidence': 0.85
        }

    def _handle_decision(self, request: str, context: Dict) -> Dict:
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø¹Ø¨Ø± Unified Cognition"""
        # For now, simple response
        # TODO: Integrate with unified_cognition.process_request()

        return {
            'response': f"Decision analysis for: {request}",
            'confidence': 0.7
        }

    def get_status(self) -> BrainHubStatus:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø­Ø§Ù„Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº"""
        return BrainHubStatus(
            active=self.is_ready,
            cognition_score=self.cognition_score,
            active_ministers=self.active_ministers_count,
            deep_cognition_available=HAS_DEEP_COGNITION,
            agent_brain_available=HAS_AGENT_BRAIN,
            government_available=HAS_GOVERNMENT,
            unified_cognition_available=HAS_UNIFIED_COGNITION,
            timestamp=datetime.now().isoformat()
        )

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø´Ø§Ù…Ù„Ø©"""
        stats = {
            'brain_hub': {
                'total_requests': self.total_requests,
                'successful_requests': self.successful_requests,
                'success_rate': self.successful_requests / max(1, self.total_requests),
                'cognition_score': self.cognition_score
            },
            'systems': {
                'deep_cognition': HAS_DEEP_COGNITION,
                'agent_brain': HAS_AGENT_BRAIN,
                'government': HAS_GOVERNMENT,
                'unified_cognition': HAS_UNIFIED_COGNITION
            }
        }

        # Add ministers stats
        if self.ministers_system:
            stats['ministers'] = self.ministers_system.get_all_stats()

        # Add unified cognition stats
        if self.unified_cognition:
            stats['unified_cognition'] = self.unified_cognition.get_system_health()

        return stats

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # METHODS FOR MINISTERS - Deep Cognition Integration
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def inference(self, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Deep Cognition

        ÙŠØ³ØªØ®Ø¯Ù…Ù‡ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ø±ÙÙŠ Ø¹Ù…ÙŠÙ‚

        Args:
            data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ­Ù„ÙŠÙ„Ù‡Ø§

        Returns:
            Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ù† Deep Cognition
        """
        if not self.is_ready:
            return None

        result = {}

        # Use Semantic Intent if text provided
        if 'text' in data or 'topic' in data:
            text = data.get('text') or data.get('topic', '')
            if self.semantic_intent and text:
                analysis = self.semantic_intent.analyze(str(text))
                result['semantic_analysis'] = {
                    'semantic_layer': analysis.semantic.layer.value,
                    'intent_layer': analysis.intent.layer.value,
                    'emotional_tone': analysis.emotional.tone.value,
                    'alignment': analysis.semantic_intent_alignment,
                    'interpretation': analysis.interpreted_meaning
                }

        # Use Meta Confidence if confidence calculation requested
        if 'confidence_factors' in data:
            factors = data['confidence_factors']
            if self.meta_confidence:
                confidence_result = self.meta_confidence.calculate_certainty(**factors)
                result['confidence_analysis'] = {
                    'overall_confidence': confidence_result.overall_confidence,
                    'certainty_level': confidence_result.certainty_level.value,
                    'recommendation': confidence_result.recommendation
                }

        # Use Scene Understanding if image provided
        if 'image_path' in data:
            if self.scene_understanding:
                scene_analysis = self.scene_understanding.analyze_scene(data['image_path'])
                result['scene_analysis'] = {
                    'scene_type': scene_analysis.scene_context.scene_type.value,
                    'lighting': scene_analysis.scene_context.lighting_condition.value,
                    'complexity': scene_analysis.complexity_score
                }

        return result if result else None

    @property
    def ai_engine(self):
        """
        AI Engine Ù…Ø­Ø§ÙƒÙŠ Ù„Ù€ compatibility Ù…Ø¹ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ù‚Ø¯Ø§Ù…Ù‰

        ÙŠÙˆÙØ±:
        - process(): Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø§Ù…Ø©
        - reasoning.reason(): Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ù†Ø·Ù‚ÙŠ
        """
        return AIEngineProxy(self)


class AIEngineProxy:
    """
    Ù…Ø­Ø§ÙƒÙŠ AI Engine Ù„Ù„ØªÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ù„ÙˆØ²Ø±Ø§Ø¡ Ø§Ù„Ù‚Ø¯Ø§Ù…Ù‰
    """

    def __init__(self, brain_hub: 'UnifiedBrainHub'):
        self.brain_hub = brain_hub
        self.reasoning = ReasoningProxy(brain_hub)

    def process(self, data: Dict[str, Any], context: str = None) -> Optional[Dict[str, Any]]:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¹Ø§Ù…Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Deep Cognition

        Args:
            data: Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§
            context: Ø§Ù„Ø³ÙŠØ§Ù‚ (development, analysis, etc.)

        Returns:
            Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        """
        result = {'context': context}

        # Use semantic intent for text processing
        if 'text' in data or 'feature' in data:
            text = data.get('text') or data.get('feature', '')
            if self.brain_hub.semantic_intent:
                analysis = self.brain_hub.semantic_intent.analyze(str(text))
                result['suggestions'] = [
                    f"Approach 1: {analysis.interpreted_meaning}",
                    f"Approach 2: Alternative implementation",
                    f"Approach 3: Optimized solution"
                ]
                result['confidence'] = analysis.semantic_intent_alignment

        return result


class ReasoningProxy:
    """Ù…Ø­Ø§ÙƒÙŠ Reasoning Engine"""

    def __init__(self, brain_hub: 'UnifiedBrainHub'):
        self.brain_hub = brain_hub

    def reason(self, data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ù…Ù†Ø·Ù‚ÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Meta Confidence

        Args:
            data: Ø§Ù„Ù…Ø´ÙƒÙ„Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø­Ù„Ù‡Ø§

        Returns:
            Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„
        """
        if not self.brain_hub.meta_confidence:
            return None

        # Use meta confidence to evaluate reasoning strength
        confidence_result = self.brain_hub.meta_confidence.calculate_certainty(
            data_quality=0.8,
            model_agreement=0.85,
            historical_accuracy=0.9,
            context_clarity=0.88
        )

        return {
            'reasoning_steps': [
                "1. Analyze problem structure",
                "2. Identify key constraints",
                "3. Evaluate possible solutions",
                "4. Select optimal approach",
                "5. Validate solution"
            ],
            'confidence': confidence_result.overall_confidence,
            'certainty_level': confidence_result.certainty_level.value,
            'recommendation': confidence_result.recommendation
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# SINGLETON INSTANCE
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

_brain_hub = None

def get_brain_hub(enable_gpu: bool = True) -> UnifiedBrainHub:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯ (Singleton)"""
    global _brain_hub
    if _brain_hub is None:
        _brain_hub = UnifiedBrainHub(enable_gpu=enable_gpu)
    return _brain_hub


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# TEST FUNCTION
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

def test_brain_hub():
    """Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±ÙƒØ² Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ù…ÙˆØ­Ø¯"""
    print("\n" + "=" * 70)
    print("ğŸ§ª TESTING UNIFIED BRAIN HUB")
    print("=" * 70 + "\n")

    # Initialize
    brain_hub = get_brain_hub(enable_gpu=True)

    # Check status
    status = brain_hub.get_status()
    print("\nğŸ“Š Brain Hub Status:")
    print(f"   Active: {status.active}")
    print(f"   Cognition Score: {status.cognition_score:.1%}")
    print(f"   Active Ministers: {status.active_ministers}")
    print(f"   Deep Cognition: {status.deep_cognition_available}")
    print(f"   Agent Brain: {status.agent_brain_available}")
    print(f"   Government: {status.government_available}")

    # Test requests
    print("\n" + "=" * 70)
    print("ğŸ§ª Testing Request Processing")
    print("=" * 70 + "\n")

    test_requests = [
        "ÙÙ‡Ù… Ù…Ø¹Ù†Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ù†Øµ: Ø§Ù„Ø­ÙŠØ§Ø© Ø¬Ù…ÙŠÙ„Ø©",
        "Ø£Ø±ÙŠØ¯ ØªØ¹Ù„ÙŠÙ… Ø§Ù„Ø·Ù„Ø§Ø¨ Ø¹Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ",
        "Ø®Ø·Ø© Ù„Ø¨Ù†Ø§Ø¡ Ù†Ø¸Ø§Ù… Ù…ÙˆØ²Ø¹"
    ]

    for request in test_requests:
        print(f"\nğŸ“ Request: {request}")
        result = brain_hub.process_request(request)
        print(f"   Status: {result.status}")
        print(f"   Confidence: {result.confidence:.0%}")
        if result.minister_used:
            print(f"   Minister: {result.minister_used}")

    # Statistics
    print("\n" + "=" * 70)
    print("ğŸ“Š Final Statistics")
    print("=" * 70 + "\n")

    stats = brain_hub.get_statistics()
    print(f"Total Requests: {stats['brain_hub']['total_requests']}")
    print(f"Success Rate: {stats['brain_hub']['success_rate']:.0%}")

    print("\nâœ… TEST COMPLETE")
    print("=" * 70 + "\n")


if __name__ == "__main__":
    test_brain_hub()
