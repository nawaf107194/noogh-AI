"""
Brain Structure Analyzer - Advanced Neural Network Inspection
ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù…Ù‚ Ù„Ù‡ÙŠÙƒÙ„ Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø¹ØµØ¨ÙŠ MegaBrain V5
"""

import torch
import json
from pathlib import Path
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging

logger = logging.getLogger(__name__)


class BrainAnalyzer:
    """Ù…Ø­Ù„Ù„ Ù…ØªÙ‚Ø¯Ù… Ù„Ù‡ÙŠÙƒÙ„ ÙˆØ£Ø¯Ø§Ø¡ Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø¹ØµØ¨ÙŠ"""

    def __init__(self, checkpoint_dir: str = "/home/noogh/brain_checkpoints"):
        self.checkpoint_dir = Path(checkpoint_dir)
        self.brain_model = None
        self.training_history = None

    def load_brain(self, model_path: Optional[str] = None) -> bool:
        """ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¯Ù…Ø§Øº Ù„Ù„ØªØ­Ù„ÙŠÙ„"""
        try:
            if model_path is None:
                model_path = self.checkpoint_dir / "best_model.pt"
            else:
                model_path = Path(model_path)

            if not model_path.exists():
                logger.warning(f"Model not found: {model_path}")
                return False

            self.brain_model = torch.load(model_path, map_location='cpu')
            logger.info(f"âœ… Brain model loaded: {model_path}")
            return True

        except Exception as e:
            logger.error(f"Failed to load brain: {e}")
            return False

    def load_training_history(self) -> bool:
        """ØªØ­Ù…ÙŠÙ„ Ø³Ø¬Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            history_path = self.checkpoint_dir / "training_history.json"
            if not history_path.exists():
                return False

            with open(history_path, 'r') as f:
                self.training_history = json.load(f)
            return True

        except Exception as e:
            logger.error(f"Failed to load training history: {e}")
            return False

    def analyze_architecture(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø¹Ù…Ø§Ø±ÙŠ ÙƒØ§Ù…Ù„ Ù„Ù„Ø´Ø¨ÙƒØ© Ø§Ù„Ø¹ØµØ¨ÙŠØ©"""
        if self.brain_model is None:
            self.load_brain()

        if self.brain_model is None:
            return {"error": "No brain model loaded"}

        analysis = {
            "timestamp": datetime.now().isoformat(),
            "model_type": "MegaBrain V5",
            "layers": [],
            "total_parameters": 0,
            "trainable_parameters": 0,
            "frozen_parameters": 0,
            "model_size_mb": 0,
            "architecture_summary": {}
        }

        try:
            # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª
            layer_types = {}
            total_params = 0
            trainable_params = 0

            for name, param in self.brain_model.items():
                if isinstance(param, torch.Tensor):
                    params = param.numel()
                    total_params += params

                    # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø©
                    layer_type = self._identify_layer_type(name)
                    if layer_type not in layer_types:
                        layer_types[layer_type] = {
                            "count": 0,
                            "parameters": 0,
                            "layers": []
                        }

                    layer_types[layer_type]["count"] += 1
                    layer_types[layer_type]["parameters"] += params
                    layer_types[layer_type]["layers"].append({
                        "name": name,
                        "shape": list(param.shape),
                        "parameters": params,
                        "dtype": str(param.dtype)
                    })

                    analysis["layers"].append({
                        "name": name,
                        "type": layer_type,
                        "shape": list(param.shape),
                        "parameters": params,
                        "dtype": str(param.dtype),
                        "device": str(param.device)
                    })

            analysis["total_parameters"] = total_params
            analysis["trainable_parameters"] = total_params  # All params trainable by default
            analysis["architecture_summary"] = layer_types

            # Ø­Ø³Ø§Ø¨ Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_path = self.checkpoint_dir / "best_model.pt"
            if model_path.exists():
                analysis["model_size_mb"] = model_path.stat().st_size / (1024 * 1024)

            return analysis

        except Exception as e:
            logger.error(f"Architecture analysis failed: {e}")
            return {"error": str(e)}

    def _identify_layer_type(self, layer_name: str) -> str:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ø·Ø¨Ù‚Ø© Ù…Ù† Ø§Ø³Ù…Ù‡Ø§"""
        name_lower = layer_name.lower()

        if 'embedding' in name_lower:
            return "Embedding"
        elif 'attention' in name_lower:
            return "Attention"
        elif 'transformer' in name_lower:
            return "Transformer"
        elif 'conv' in name_lower:
            return "Convolution"
        elif 'bn' in name_lower or 'batch_norm' in name_lower:
            return "BatchNorm"
        elif 'linear' in name_lower or 'fc' in name_lower:
            return "Linear"
        elif 'lstm' in name_lower or 'gru' in name_lower:
            return "RNN"
        elif 'weight' in name_lower:
            return "Weight"
        elif 'bias' in name_lower:
            return "Bias"
        else:
            return "Other"

    def analyze_training_progress(self) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡"""
        if self.training_history is None:
            self.load_training_history()

        if self.training_history is None:
            return {"error": "No training history available"}

        try:
            analysis = {
                "timestamp": datetime.now().isoformat(),
                "training_completed": True,
                "total_epochs": len(self.training_history.get("train_losses", [])),
                "metrics": {},
                "improvements": {},
                "performance_trend": ""
            }

            train_losses = self.training_history.get("train_loss", self.training_history.get("train_losses", []))
            val_losses = self.training_history.get("val_loss", self.training_history.get("val_losses", []))

            if train_losses and val_losses:
                # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
                initial_train_loss = train_losses[0] if train_losses else 0
                final_train_loss = train_losses[-1] if train_losses else 0
                initial_val_loss = val_losses[0] if val_losses else 0
                final_val_loss = val_losses[-1] if val_losses else 0

                train_improvement = ((initial_train_loss - final_train_loss) / initial_train_loss * 100) if initial_train_loss > 0 else 0
                val_improvement = ((initial_val_loss - final_val_loss) / initial_val_loss * 100) if initial_val_loss > 0 else 0

                analysis["metrics"] = {
                    "initial_train_loss": round(initial_train_loss, 4),
                    "final_train_loss": round(final_train_loss, 4),
                    "initial_val_loss": round(initial_val_loss, 4),
                    "final_val_loss": round(final_val_loss, 4),
                    "best_val_loss": round(min(val_losses), 4),
                    "avg_train_loss": round(sum(train_losses) / len(train_losses), 4),
                    "avg_val_loss": round(sum(val_losses) / len(val_losses), 4)
                }

                analysis["improvements"] = {
                    "train_loss_improvement_pct": round(train_improvement, 2),
                    "val_loss_improvement_pct": round(val_improvement, 2),
                    "generalization_gap": round(final_val_loss - final_train_loss, 4)
                }

                # ØªØ­Ø¯ÙŠØ¯ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø£Ø¯Ø§Ø¡
                if val_improvement > 80:
                    analysis["performance_trend"] = "Ù…Ù…ØªØ§Ø² - ØªØ­Ø³Ù† ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹"
                elif val_improvement > 60:
                    analysis["performance_trend"] = "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ - ØªØ­Ø³Ù† Ù…Ù„Ø­ÙˆØ¸"
                elif val_improvement > 40:
                    analysis["performance_trend"] = "Ø¬ÙŠØ¯ - ØªØ­Ø³Ù† Ù…Ø³ØªÙ…Ø±"
                elif val_improvement > 20:
                    analysis["performance_trend"] = "Ù…Ù‚Ø¨ÙˆÙ„ - ØªØ­Ø³Ù† Ù…Ø¹ØªØ¯Ù„"
                else:
                    analysis["performance_trend"] = "Ø¶Ø¹ÙŠÙ - ØªØ­Ø³Ù† Ù…Ø­Ø¯ÙˆØ¯"

            return analysis

        except Exception as e:
            logger.error(f"Training analysis failed: {e}")
            return {"error": str(e)}

    def get_brain_health_score(self) -> Dict[str, Any]:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¤Ø´Ø± ØµØ­Ø© Ø§Ù„Ø¯Ù…Ø§Øº Ø§Ù„Ø´Ø§Ù…Ù„"""
        architecture = self.analyze_architecture()
        training = self.analyze_training_progress()

        health_score = {
            "timestamp": datetime.now().isoformat(),
            "overall_health": 0,
            "components": {},
            "status": "unknown",
            "recommendations": []
        }

        try:
            scores = {}

            # 1. Architecture Health (30%)
            if "error" not in architecture:
                arch_score = 100  # Base score
                total_params = architecture.get("total_parameters", 0)

                # Penalize if too small or too large
                if total_params < 1_000_000:
                    arch_score -= 20
                    health_score["recommendations"].append("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹ - ÙÙƒØ± ÙÙŠ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø³Ø¹Ø©")
                elif total_params > 100_000_000:
                    arch_score -= 10
                    health_score["recommendations"].append("Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙƒØ¨ÙŠØ± Ø¬Ø¯Ø§Ù‹ - Ù‚Ø¯ ÙŠØ­ØªØ§Ø¬ optimization")

                scores["architecture"] = max(0, arch_score)

            # 2. Training Performance (40%)
            if "error" not in training and "improvements" in training:
                val_improvement = training["improvements"].get("val_loss_improvement_pct", 0)

                if val_improvement > 80:
                    scores["training"] = 100
                elif val_improvement > 60:
                    scores["training"] = 85
                elif val_improvement > 40:
                    scores["training"] = 70
                elif val_improvement > 20:
                    scores["training"] = 50
                else:
                    scores["training"] = 30
                    health_score["recommendations"].append("Ø§Ù„ØªØ­Ø³Ù† ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ø­Ø¯ÙˆØ¯ - ÙÙƒØ± ÙÙŠ ØªØ¹Ø¯ÙŠÙ„ hyperparameters")

            # 3. Generalization (30%)
            if "error" not in training and "improvements" in training:
                gap = abs(training["improvements"].get("generalization_gap", 0))

                if gap < 0.02:
                    scores["generalization"] = 100
                elif gap < 0.05:
                    scores["generalization"] = 85
                elif gap < 0.1:
                    scores["generalization"] = 70
                elif gap < 0.2:
                    scores["generalization"] = 50
                else:
                    scores["generalization"] = 30
                    health_score["recommendations"].append("ÙØ¬ÙˆØ© Ø§Ù„ØªØ¹Ù…ÙŠÙ… ÙƒØ¨ÙŠØ±Ø© - Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ù‡Ù†Ø§Ùƒ overfitting")

            # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¯Ø±Ø¬Ø© Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
            if scores:
                weights = {
                    "architecture": 0.3,
                    "training": 0.4,
                    "generalization": 0.3
                }

                overall = sum(scores.get(k, 0) * weights.get(k, 0) for k in weights.keys())
                health_score["overall_health"] = round(overall, 1)
                health_score["components"] = scores

                # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø­Ø§Ù„Ø©
                if overall >= 90:
                    health_score["status"] = "Ù…Ù…ØªØ§Ø² ğŸŸ¢"
                elif overall >= 75:
                    health_score["status"] = "Ø¬ÙŠØ¯ Ø¬Ø¯Ø§Ù‹ ğŸŸ¢"
                elif overall >= 60:
                    health_score["status"] = "Ø¬ÙŠØ¯ ğŸŸ¡"
                elif overall >= 40:
                    health_score["status"] = "Ù…Ù‚Ø¨ÙˆÙ„ ğŸŸ¡"
                else:
                    health_score["status"] = "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ† ğŸ”´"

            return health_score

        except Exception as e:
            logger.error(f"Health score calculation failed: {e}")
            return {"error": str(e)}

    def generate_comprehensive_report(self) -> Dict[str, Any]:
        """ØªÙ‚Ø±ÙŠØ± Ø´Ø§Ù…Ù„ Ø¹Ù† Ø­Ø§Ù„Ø© Ø§Ù„Ø¯Ù…Ø§Øº"""
        return {
            "timestamp": datetime.now().isoformat(),
            "architecture": self.analyze_architecture(),
            "training_progress": self.analyze_training_progress(),
            "health_score": self.get_brain_health_score()
        }


# Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if __name__ == "__main__":
    analyzer = BrainAnalyzer()
    report = analyzer.generate_comprehensive_report()
    print(json.dumps(report, indent=2, ensure_ascii=False))
