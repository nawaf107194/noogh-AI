#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ðŸŒ‰ ALLaM Decision Bridge - Ø¬Ø³Ø± ALLaM Ù…Ø¹ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø±
==================================================

Integrates ALLaM (Arabic LLM) with Decision Engine for enhanced reasoning.

Author: Noogh AI Team
Version: 1.0.0
"""

import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

from decision import (
    DecisionContext,
    DecisionOption,
    DecisionType,
    DecisionPriority
)


logger = logging.getLogger(__name__)


class ALLaMDecisionBridge:
    """
    ðŸŒ‰ Ø¬Ø³Ø± Ø¨ÙŠÙ† ALLaM ÙˆÙ…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø±

    Uses ALLaM for:
    - Arabic language understanding
    - Complex reasoning
    - Generating decision options
    - Explaining decisions in Arabic
    """

    def __init__(self, use_allam: bool = True):
        self.use_allam = use_allam
        self.allam_model = None

        if use_allam:
            try:
                from brain.allam_model import ALLaMModel
                self.allam_model = ALLaMModel(backend="production")
                self.allam_model.load_model()
                logger.info("âœ… ALLaM model loaded in production mode")
            except Exception as e:
                logger.warning(f"âš ï¸ Could not load ALLaM: {e}")
                logger.info("   Falling back to rule-based reasoning")
                self.use_allam = False

        logger.info("ðŸŒ‰ ALLaM Decision Bridge initialized")

    def enhance_decision_context(
        self,
        context: DecisionContext,
        user_request: str
    ) -> DecisionContext:
        """
        ØªØ­Ø³ÙŠÙ† Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ALLaM

        Args:
            context: Ø³ÙŠØ§Ù‚ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø£ØµÙ„ÙŠ
            user_request: Ø§Ù„Ø·Ù„Ø¨ Ù…Ù† Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…

        Returns:
            Ø³ÙŠØ§Ù‚ Ù…Ø­Ø³Ù‘Ù†
        """
        if not self.use_allam or not self.allam_model:
            return context  # No enhancement

        try:
            # Use ALLaM to understand user intent better
            analysis = self._analyze_intent(user_request)

            # Enhance context with ALLaM insights
            if "intent" in analysis:
                context.metadata["allam_intent"] = analysis["intent"]

            if "entities" in analysis:
                context.metadata["allam_entities"] = analysis["entities"]

            if "sentiment" in analysis:
                context.metadata["allam_sentiment"] = analysis["sentiment"]

            logger.debug("âœ¨ Context enhanced with ALLaM insights")

        except Exception as e:
            logger.warning(f"ALLaM enhancement failed: {e}")

        return context

    def generate_options_with_allam(
        self,
        user_request: str,
        context: Dict[str, Any],
        ministers_input: Dict[str, Any]
    ) -> List[DecisionOption]:
        """
        ØªÙˆÙ„ÙŠØ¯ Ø®ÙŠØ§Ø±Ø§Øª Ù‚Ø±Ø§Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ALLaM

        Args:
            user_request: Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            context: Ø§Ù„Ø³ÙŠØ§Ù‚
            ministers_input: Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ÙˆØ²Ø±Ø§Ø¡

        Returns:
            Ø®ÙŠØ§Ø±Ø§Øª Ù‚Ø±Ø§Ø± Ù…Ù‚ØªØ±Ø­Ø© Ù…Ù† ALLaM
        """
        options = []

        if not self.use_allam or not self.allam_model:
            return options  # Return empty, let ministers handle it

        try:
            # Prepare prompt for ALLaM
            prompt = self._build_decision_prompt(
                user_request,
                ministers_input
            )

            # Get ALLaM's suggestions
            response = self._query_allam(prompt)

            # Parse response into decision options
            options = self._parse_allam_response(response)

            logger.info(f"âœ¨ ALLaM generated {len(options)} options")

        except Exception as e:
            logger.warning(f"ALLaM option generation failed: {e}")

        return options

    def explain_decision_in_arabic(
        self,
        decision_action: str,
        reasoning: List[str],
        context: Dict[str, Any]
    ) -> str:
        """
        Ø´Ø±Ø­ Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… ALLaM

        Args:
            decision_action: Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù…ÙØªØ®Ø°
            reasoning: Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨
            context: Ø§Ù„Ø³ÙŠØ§Ù‚

        Returns:
            Ø´Ø±Ø­ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        """
        if not self.use_allam or not self.allam_model:
            # Fallback: simple Arabic template
            return self._simple_arabic_explanation(decision_action, reasoning)

        try:
            prompt = f"""
Ø§Ø´Ø±Ø­ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„ØªØ§Ù„ÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø´ÙƒÙ„ ÙˆØ§Ø¶Ø­ ÙˆÙ…ÙØµÙ„:

Ø§Ù„Ù‚Ø±Ø§Ø±: {decision_action}
Ø§Ù„Ø£Ø³Ø¨Ø§Ø¨:
{chr(10).join('- ' + r for r in reasoning)}

Ø§ÙƒØªØ¨ Ø´Ø±Ø­Ø§Ù‹ Ù…Ø®ØªØµØ±Ø§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹ Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…:
"""

            explanation = self._query_allam(prompt)
            return explanation

        except Exception as e:
            logger.warning(f"ALLaM explanation failed: {e}")
            return self._simple_arabic_explanation(decision_action, reasoning)

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PRIVATE HELPERS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _analyze_intent(self, text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ"""

        if not self.use_allam:
            return self._rule_based_intent(text)

        # Use ALLaM for intent analysis
        prompt = f"""
Ø­Ù„Ù„ Ø§Ù„Ù†ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ Ø§Ù„ØªØ§Ù„ÙŠ:
"{text}"

Ø£Ø¹Ø· Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¨ØµÙŠØºØ© JSON:
{{
    "intent": "trading" Ø£Ùˆ "analysis" Ø£Ùˆ "learning",
    "entities": ["ÙƒÙŠØ§Ù†1", "ÙƒÙŠØ§Ù†2"],
    "sentiment": "positive" Ø£Ùˆ "negative" Ø£Ùˆ "neutral"
}}
"""

        try:
            response = self._query_allam(prompt)
            # Parse JSON response (simplified for demo)
            return self._rule_based_intent(text)  # Fallback for now
        except:
            return self._rule_based_intent(text)

    def _rule_based_intent(self, text: str) -> Dict[str, Any]:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† ALLaM"""

        text_lower = text.lower()

        # Intent
        if any(word in text_lower for word in ["ØªØ¯Ø§ÙˆÙ„", "Ø´Ø±Ø§Ø¡", "Ø¨ÙŠØ¹", "Ø§Ø³ØªØ«Ù…Ø§Ø±", "trade", "buy", "sell", "invest"]):
            intent = "trading"
        elif any(word in text_lower for word in ["ØªØ­Ù„ÙŠÙ„", "ÙØ­Øµ", "analyze", "check"]):
            intent = "analysis"
        elif any(word in text_lower for word in ["ØªØ¹Ù„Ù…", "ØªØ¯Ø±ÙŠØ¨", "learn", "train"]):
            intent = "learning"
        else:
            intent = "general"

        # Entities (simple extraction)
        entities = []
        crypto_keywords = ["bitcoin", "btc", "ethereum", "eth", "Ø¨ØªÙƒÙˆÙŠÙ†", "Ø¥ÙŠØ«ÙŠØ±ÙŠÙˆÙ…"]
        for keyword in crypto_keywords:
            if keyword in text_lower:
                entities.append(keyword)

        # Sentiment (very simple)
        positive_words = ["Ø¬ÙŠØ¯", "Ù…Ù…ØªØ§Ø²", "Ø±Ø§Ø¦Ø¹", "good", "great", "excellent"]
        negative_words = ["Ø³ÙŠØ¡", "Ø®Ø·ÙŠØ±", "bad", "risky"]

        if any(word in text_lower for word in positive_words):
            sentiment = "positive"
        elif any(word in text_lower for word in negative_words):
            sentiment = "negative"
        else:
            sentiment = "neutral"

        return {
            "intent": intent,
            "entities": entities,
            "sentiment": sentiment
        }

    def _build_decision_prompt(
        self,
        user_request: str,
        ministers_input: Dict[str, Any]
    ) -> str:
        """Ø¨Ù†Ø§Ø¡ prompt Ù„Ù€ ALLaM"""

        prompt = f"""
Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø°ÙƒÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª.

Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_request}

ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡:
"""

        for minister, data in ministers_input.items():
            if isinstance(data, dict):
                recs = data.get("recommendations", [])
                if recs:
                    prompt += f"\n{minister}:\n"
                    for rec in recs[:2]:  # Top 2
                        if isinstance(rec, dict):
                            prompt += f"  - {rec.get('description', rec.get('action', ''))}\n"

        prompt += """
Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø£Ø¹Ù„Ø§Ù‡ØŒ Ø§Ù‚ØªØ±Ø­ 2-3 Ø®ÙŠØ§Ø±Ø§Øª Ù„Ù„Ù‚Ø±Ø§Ø± Ù…Ø¹ Ø´Ø±Ø­ Ù…Ø®ØªØµØ± Ù„ÙƒÙ„ Ø®ÙŠØ§Ø±.
"""

        return prompt

    def _query_allam(self, prompt: str) -> str:
        """Ø§Ø³ØªØ¹Ù„Ø§Ù… ALLaM"""

        if not self.allam_model:
            raise Exception("ALLaM model not loaded")

        # For demo mode, return simulated response
        if self.allam_model.backend == "demo":
            return self._simulate_allam_response(prompt)

        # Real ALLaM inference
        try:
            response = self.allam_model.generate(
                prompt=prompt,
                max_new_tokens=200,
                temperature=0.7
            )
            return response
        except Exception as e:
            logger.error(f"ALLaM query failed: {e}")
            return ""

    def _simulate_allam_response(self, prompt: str) -> str:
        """Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ¬Ø§Ø¨Ø© ALLaM ÙÙŠ ÙˆØ¶Ø¹ Demo"""

        # Simple simulated responses based on keywords
        if "Ù‚Ø±Ø§Ø±" in prompt or "Ø®ÙŠØ§Ø±" in prompt:
            return """
Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:
1. ØªÙ†ÙÙŠØ° Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªÙˆØµÙŠØ© Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡ (Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©)
2. Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± ÙˆØ¬Ù…Ø¹ Ø§Ù„Ù…Ø²ÙŠØ¯ Ù…Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª (Ø­Ø°Ø±)
3. Ø·Ù„Ø¨ Ø±Ø£ÙŠ Ø¥Ø¶Ø§ÙÙŠ Ù…Ù† Ù…Ø³ØªØ´Ø§Ø±ÙŠÙ† Ø¢Ø®Ø±ÙŠÙ† (Ù…ØªÙˆØ§Ø²Ù†)
"""
        elif "Ø´Ø±Ø­" in prompt:
            return "ØªÙ… Ø§ØªØ®Ø§Ø° Ù‡Ø°Ø§ Ø§Ù„Ù‚Ø±Ø§Ø± Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© ÙˆØªÙˆØµÙŠØ§Øª Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡ØŒ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø° Ø¨Ø¹ÙŠÙ† Ø§Ù„Ø§Ø¹ØªØ¨Ø§Ø± Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„ÙÙˆØ§Ø¦Ø¯ Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©."
        else:
            return "ÙÙ‡Ù…Øª Ø·Ù„Ø¨Ùƒ. Ø³Ø£Ø¹Ù…Ù„ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„Ù‡ Ø¨Ø¹Ù†Ø§ÙŠØ©."

    def _parse_allam_response(self, response: str) -> List[DecisionOption]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ¬Ø§Ø¨Ø© ALLaM ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ù„Ø®ÙŠØ§Ø±Ø§Øª Ù‚Ø±Ø§Ø±"""

        options = []

        # Simple parsing (for demo)
        # In production, would use more sophisticated parsing

        lines = response.strip().split('\n')
        option_id = 0

        for line in lines:
            line = line.strip()
            if line and (line.startswith('1.') or line.startswith('2.') or line.startswith('3.')):
                # Extract option text
                option_text = line[2:].strip()

                # Create decision option
                option = DecisionOption(
                    option_id=f"ALLAM-{option_id}",
                    action=f"allam_suggestion_{option_id}",
                    description=option_text,
                    confidence=0.75,  # Default confidence from ALLaM
                    reasoning=[f"ALLaM suggestion based on Arabic understanding"]
                )

                options.append(option)
                option_id += 1

        return options

    def _simple_arabic_explanation(
        self,
        action: str,
        reasoning: List[str]
    ) -> str:
        """Ø´Ø±Ø­ Ø¨Ø³ÙŠØ· Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø¯ÙˆÙ† ALLaM"""

        explanation = f"ØªÙ… Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±: {action}\n\nØ§Ù„Ø£Ø³Ø¨Ø§Ø¨:\n"

        for i, reason in enumerate(reasoning[:3], 1):
            explanation += f"{i}. {reason}\n"

        return explanation


# Singleton
_allam_bridge = None

def get_allam_bridge(use_allam: bool = True) -> ALLaMDecisionBridge:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ø³Ø± ALLaM"""
    global _allam_bridge
    if _allam_bridge is None:
        _allam_bridge = ALLaMDecisionBridge(use_allam=use_allam)
    return _allam_bridge
