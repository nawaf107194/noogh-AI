#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ§ ğŸŒ‰ Cognitive Decision Bridge - Ø¬Ø³Ø± Ø§Ù„Ø¥Ø¯Ø±Ø§Ùƒ Ù…Ø¹ Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø±
==========================================================

Integrates Cognitive Core (4096-neuron brain + self-improvement)
with Decision Engine (government ministers + decision making).

This creates a complete cognitive loop:
Decision â†’ Neural Processing â†’ Storage â†’ Analysis â†’ Improvement â†’ Better Decision

Author: Noogh AI Team
Version: 3.0.0
"""

import logging
import torch
from typing import Dict, List, Any, Optional
from datetime import datetime
from pathlib import Path

from ..decision import (
    DecisionEngine,
    DecisionContext,
    DecisionOption,
    DecisionType,
    DecisionPriority,
    get_decision_engine
)

from ..brain.unified_brain import create_brain, UnifiedNooghBrain


logger = logging.getLogger(__name__)


class CognitiveDecisionBridge:
    """
    ğŸ§ ğŸŒ‰ Ø¬Ø³Ø± Ù…ØªÙƒØ§Ù…Ù„ Ø¨ÙŠÙ† Ø§Ù„Ø¥Ø¯Ø±Ø§Ùƒ ÙˆØ§Ù„Ù‚Ø±Ø§Ø± (v4.0 - Unified Brain)

    ÙŠØ±Ø¨Ø· Ø¨ÙŠÙ†:
    1. UnifiedNooghBrain (MegaBrain V5) - Ø§Ù„ÙÙ‡Ù… Ø§Ù„Ø¹Ù…ÙŠÙ‚
    2. Decision Engine - ØµÙ†Ø¹ Ø§Ù„Ù‚Ø±Ø§Ø±
    3. Government System - Ø§Ù„ÙˆØ²Ø±Ø§Ø¡

    Ø§Ù„Ù†ØªÙŠØ¬Ø©:
    - Ù†Ø¸Ø§Ù… Ù‚Ø±Ø§Ø± Ø°ÙƒÙŠ ÙŠØªØ­Ø³Ù† ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ØªÙŠ Ø§Ù„Ù…Ø¯Ù…Ø¬
    """

    def __init__(
        self,
        unified_brain: Optional[UnifiedNooghBrain] = None,
        decision_engine: Optional[DecisionEngine] = None
    ):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ

        Args:
            unified_brain: Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙˆØ­Ø¯
            decision_engine: Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚Ø±Ø§Ø±
        """

        # Initialize unified brain
        if unified_brain is None:
            logger.info("ğŸ§  Creating Unified Noogh Brain...")
            self.unified_brain = create_brain(use_autonomous=True)
            # Create a default model for inference if none exists
            if not self.unified_brain.is_ready:
                self.unified_brain.create_mega_brain(config="micro")
        else:
            self.unified_brain = unified_brain

        # Initialize decision engine
        if decision_engine is None:
            self.decision_engine = get_decision_engine()
        else:
            self.decision_engine = decision_engine

        # Statistics
        self.total_decisions = 0
        self.cognitive_enhanced_decisions = 0

        logger.info("âœ… Cognitive Decision Bridge initialized (Unified Brain)")
        brain_info = self.unified_brain.get_system_info()
        model_stats = brain_info.get("model", {}).get("stats", {})
        logger.info(f"   Model: {model_stats.get('model_name', 'N/A')}")
        logger.info(f"   Parameters: {model_stats.get('parameters_millions', 0):.2f}M")
        logger.info(f"   Autonomous System: {'âœ…' if self.unified_brain.use_autonomous else 'âŒ'}")

    def process_government_decision(
        self,
        user_request: str,
        ministers_analysis: Dict[str, Any],
        priority: str = "MEDIUM",
        decision_type: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Ù…Ø¹Ø§Ù„Ø¬Ø© Ù‚Ø±Ø§Ø± Ø­ÙƒÙˆÙ…ÙŠ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø¹Ø±ÙÙŠ

        Ù‡Ø°Ù‡ Ø§Ù„Ø¯Ø§Ù„Ø© Ù‡ÙŠ Ø§Ù„Ù†Ù‚Ø·Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ© Ø§Ù„ØªÙŠ ØªØ¬Ù…Ø¹ ÙƒÙ„ Ø´ÙŠØ¡:

        Flow:
        1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨ Ø¹Ø¨Ø± Neural Brain (4096 neurons)
        2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ options Ù…Ù† Ø§Ù„ÙˆØ²Ø±Ø§Ø¡
        3. ØµÙ†Ø¹ Ø§Ù„Ù‚Ø±Ø§Ø± Ø¹Ø¨Ø± Decision Engine
        4. Ø­ÙØ¸ Ø§Ù„Ù‚Ø±Ø§Ø± ÙÙŠ Memory Vault
        5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ (Ø¹Ù†Ø¯ ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù€ outcome)
        6. ØªØ­Ø³ÙŠÙ† Ø°Ø§ØªÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠ ÙƒÙ„ 24 Ø³Ø§Ø¹Ø©

        Args:
            user_request: Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            ministers_analysis: ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙˆØ²Ø±Ø§Ø¡
            priority: CRITICAL, HIGH, MEDIUM, LOW, INFO
            decision_type: Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø±Ø§Ø± (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ + Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ø¹Ø±ÙÙŠØ©
        """

        logger.info("=" * 70)
        logger.info("ğŸ§  COGNITIVE DECISION PROCESSING")
        logger.info("=" * 70)

        self.total_decisions += 1

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 1: Neural Processing (Unified Brain)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 1: Neural processing (Unified Brain)...")

        # The new brain takes a dictionary as input
        # In a real scenario, this would be a proper feature vector
        dummy_input = {"user_request": user_request}
        neural_output = self.unified_brain.inference(dummy_input)

        # Extract neural insights
        neural_insights = {
            "confidence": torch.sigmoid(neural_output).mean().item() if neural_output is not None else 0.5,
        }

        logger.info(f"   Neural confidence: {neural_insights['confidence']:.2%}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 2: Decision Context Creation
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 2: Creating decision context...")

        # Determine decision type
        inferred_decision_type = self._infer_decision_type(ministers_analysis)
        final_decision_type = decision_type or inferred_decision_type.value

        # Create context
        context = DecisionContext(
            request_id=f"COG-{int(datetime.now().timestamp())}",
            timestamp=datetime.now(),
            decision_type=final_decision_type,
            priority=DecisionPriority[priority.upper()],
            user_request=user_request,
            ministers_input=ministers_analysis,
            current_state={},
            metadata={
                "neural_confidence": neural_insights["confidence"],
                "cognitive_enhanced": True,
                "brain_version": "v3.0_4096neurons"
            }
        )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 3: Extract Options from Ministers
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 3: Extracting minister options...")

        options = self._extract_minister_options(ministers_analysis, neural_insights)

        logger.info(f"   Extracted {len(options)} options from ministers")

        if not options:
            logger.warning("   No options from ministers, creating defaults")
            options = self._create_default_options(user_request)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 4: Make Decision (Decision Engine)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 4: Making decision...")

        decision = self.decision_engine.make_decision(context, options)

        logger.info(f"   Decision: {decision.selected_option.action}")
        logger.info(f"   Confidence: {decision.confidence:.2%}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 5: Cognitive Processing (Knowledge Graph)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 5: Cognitive processing (knowledge graph)...")

        # Extract ministers involved
        ministers_involved = list(ministers_analysis.keys())
        
        # Add decision to knowledge graph
        record_id = f"decision_{decision.decision_id}"
        self.unified_brain.add_knowledge(record_id, data={
            "type": "decision",
            "request": user_request,
            "decision": decision.selected_option.action,
            "confidence": decision.confidence,
            "ministers": ministers_involved,
            "timestamp": decision.timestamp.isoformat()
        })

        self.cognitive_enhanced_decisions += 1

        logger.info(f"   Stored in knowledge graph: {record_id}")

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # STEP 6: Prepare Response
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

        logger.info("Step 6: Preparing response...")

        brain_info = self.unified_brain.get_system_info()
        model_stats = brain_info.get("model", {}).get("stats", {})

        response = {
            # Decision info
            "decision_id": decision.decision_id,
            "cognitive_record_id": record_id,
            "action": decision.selected_option.action,
            "description": decision.selected_option.description,
            "confidence": decision.confidence,
            "should_execute": decision.should_execute,

            # Reasoning
            "reasoning": decision.reasoning,
            "alternatives": [
                {
                    "action": alt.action,
                    "confidence": alt.confidence,
                    "description": alt.description
                }
                for alt in decision.alternatives
            ],

            # Neural insights
            "neural_insights": {
                "brain_confidence": neural_insights["confidence"],
                "model_name": model_stats.get("model_name"),
                "parameters_millions": model_stats.get("parameters_millions", 0)
            },

            # Cognitive insights
            "cognitive_insights": {
                "record_id": record_id,
                "knowledge_nodes": brain_info.get("knowledge", {}).get("nodes", 0),
                "autonomous_system_active": self.unified_brain.use_autonomous,
            },

            # Ministers involved
            "ministers_involved": ministers_involved,

            # Timestamps
            "timestamp": decision.timestamp.isoformat(),
            "decision_time_ms": decision.decision_time_ms
        }

        logger.info("=" * 70)
        logger.info("âœ… COGNITIVE DECISION COMPLETE")
        logger.info("=" * 70)

        return response

    def record_outcome(
        self,
        decision_id: str,
        cognitive_record_id: str,
        success: bool,
        user_feedback: Optional[str] = None,
        user_rating: Optional[float] = None,
        metrics: Optional[Dict] = None
    ):
        """
        ØªØ³Ø¬ÙŠÙ„ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù‚Ø±Ø§Ø±

        Ù‡Ø°Ø§ ÙŠÙÙØ¹Ù‘Ù„:
        1. ØªØ­Ø¯ÙŠØ« Knowledge Graph
        2. Ù‚Ø¯ ÙŠÙÙØ¹Ù‘Ù„ ØªØ¯Ø±ÙŠØ¨ Ø°Ø§ØªÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙØ´Ù„ Ø­Ø±Ø¬
        """

        logger.info("=" * 70)
        logger.info("ğŸ“ RECORDING OUTCOME")
        logger.info("=" * 70)

        if metrics is None:
            metrics = {}

        # Record in Decision Engine
        self.decision_engine.record_outcome(decision_id, success, metrics)

        # Update knowledge graph with outcome
        outcome = "success" if success else "failure"
        outcome_score = user_rating if user_rating is not None else (1.0 if success else 0.0)
        
        self.unified_brain.add_knowledge(cognitive_record_id, data={
            "outcome": outcome,
            "outcome_score": outcome_score,
            "user_feedback": user_feedback,
            "metrics": metrics
        })

        logger.info(f"   Outcome: {outcome}")
        logger.info(f"   Score: {outcome_score:.2f}")
        if user_feedback:
            logger.info(f"   Feedback: {user_feedback[:100]}")

        # The autonomous system in UnifiedNooghBrain will handle improvements
        if not success and self.unified_brain.use_autonomous:
            logger.warning("âš ï¸ Critical failure detected! Autonomous system will handle it.")

        logger.info("=" * 70)
        logger.info("âœ… OUTCOME RECORDED")
        logger.info("=" * 70)

    def get_daily_reflection(self) -> Dict[str, Any]:
        """
        Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ ØªØ£Ù…Ù„ ÙŠÙˆÙ…ÙŠ
        NOTE: This is now handled by the autonomous system within UnifiedNooghBrain.
        This method provides a summary from the brain's perspective.
        """
        logger.info("ğŸ” Generating daily reflection from Unified Brain...")
        # This is a simplified representation. A real implementation would query
        # the brain's knowledge graph for performance metrics.
        return self.unified_brain.get_system_info()

    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # PRIVATE HELPERS
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    def _infer_decision_type(self, ministers_data: Dict) -> DecisionType:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù†ÙˆØ¹ Ø§Ù„Ù‚Ø±Ø§Ø± Ù…Ù† Ø§Ù„ÙˆØ²Ø±Ø§Ø¡"""
        ministers = set(ministers_data.keys())
        if any(m in ministers for m in ["finance", "quantitative", "technical_analysis", "portfolio"]):
            return DecisionType.TRADING
        if any(m in ministers for m in ["training", "research"]):
            return DecisionType.LEARNING
        if any(m in ministers for m in ["resource", "performance"]):
            return DecisionType.RESOURCE
        if "security" in ministers or "privacy" in ministers:
            return DecisionType.SECURITY
        return DecisionType.ANALYSIS

    def _extract_minister_options(
        self,
        ministers_data: Dict[str, Any],
        neural_insights: Dict[str, Any]
    ) -> List[DecisionOption]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ù…Ù† ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„ÙˆØ²Ø±Ø§Ø¡"""
        options = []
        option_id = 0
        for minister, data in ministers_data.items():
            if not isinstance(data, dict):
                continue
            recommendations = data.get("recommendations", []) or data.get("actions", []) or data.get("suggestions", [])
            for rec in recommendations:
                if isinstance(rec, str):
                    option = DecisionOption(
                        option_id=f"OPT-{option_id}",
                        action=rec,
                        description=f"{minister} suggests: {rec}",
                        confidence=data.get("confidence", 0.5)
                    )
                elif isinstance(rec, dict):
                    base_confidence = rec.get("confidence", 0.5)
                    neural_boost = neural_insights["confidence"] * 0.2
                    adjusted_confidence = min(1.0, base_confidence + neural_boost)
                    option = DecisionOption(
                        option_id=f"OPT-{option_id}",
                        action=rec.get("action", "unknown"),
                        description=rec.get("description", ""),
                        confidence=adjusted_confidence,
                        expected_value=rec.get("expected_value", 0.0),
                        risk_score=rec.get("risk", 0.0),
                        cost=rec.get("cost", 0.0)
                    )
                    option.reasoning = rec.get("reasoning", [])
                option.ministers_votes[minister] = data.get("confidence", 0.5)
                option.supporting_evidence["neural_enhanced"] = True
                option.supporting_evidence["neural_confidence"] = neural_insights["confidence"]
                options.append(option)
                option_id += 1
        return options

    def _create_default_options(self, user_request: str) -> List[DecisionOption]:
        """Ø®ÙŠØ§Ø±Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        return [
            DecisionOption(
                option_id="DEFAULT-1",
                action="analyze_further",
                description="Analyze the request in more detail using neural brain",
                confidence=0.6,
                risk_score=0.1
            ),
            DecisionOption(
                option_id="DEFAULT-2",
                action="request_clarification",
                description="Ask user for more information",
                confidence=0.5,
                risk_score=0.0
            )
        ]


# Singleton
_bridge = None

def get_cognitive_decision_bridge() -> CognitiveDecisionBridge:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ø³Ø± Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ (Singleton)

    Returns:
        Ø§Ù„Ø¬Ø³Ø± Ø§Ù„Ù…Ø¹Ø±ÙÙŠ
    """
    global _bridge
    if _bridge is None:
        _bridge = CognitiveDecisionBridge()
    return _bridge
