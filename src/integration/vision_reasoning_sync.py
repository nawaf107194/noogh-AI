"""
Vision-Reasoning Synchronizer - Ù…ÙˆØ­Ù‘Ø¯ Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªÙÙƒÙŠØ±
========================================================

ÙŠØ±Ø¨Ø· Ø¨ÙŠÙ† Ù†Ø¸Ø§Ù… Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ© ÙˆÙ†Ø¸Ø§Ù… Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ
Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© Ø¥Ù„Ù‰ Ø±Ù…ÙˆØ² Ù…Ø¹Ø±ÙÙŠØ© Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„

Addresses Deep Cognition Q8 (Cross-modal validation)

Author: Noogh AI Team
Date: 2025-11-10
Priority: CRITICAL
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
from pathlib import Path
import os
import sys

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
sys.path.insert(0, str(Path(__file__).parent.parent.parent))


class ModalityType(str, Enum):
    """Ù†ÙˆØ¹ Ø§Ù„ÙˆØ³ÙŠØ·"""
    VISION = "vision"
    TEXT = "text"
    REASONING = "reasoning"
    COMBINED = "combined"


class SyncStatus(str, Enum):
    """Ø­Ø§Ù„Ø© Ø§Ù„ØªØ²Ø§Ù…Ù†"""
    ALIGNED = "aligned"  # Ù…ØªÙˆØ§ÙÙ‚
    PARTIAL_CONFLICT = "partial_conflict"  # ØªØ¹Ø§Ø±Ø¶ Ø¬Ø²Ø¦ÙŠ
    MAJOR_CONFLICT = "major_conflict"  # ØªØ¹Ø§Ø±Ø¶ ÙƒØ¨ÙŠØ±
    UNSYNCHRONIZED = "unsynchronized"  # ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†


@dataclass
class VisualConcept:
    """Ù…ÙÙ‡ÙˆÙ… Ø¨ØµØ±ÙŠ"""
    concept_type: str  # "object", "scene", "text", "pattern"
    label: str
    confidence: float
    bounding_box: Optional[Tuple[int, int, int, int]] = None  # (x, y, w, h)
    attributes: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ReasoningConcept:
    """Ù…ÙÙ‡ÙˆÙ… Ù…Ù†Ø·Ù‚ÙŠ"""
    concept_type: str  # "entity", "relation", "action", "state"
    label: str
    confidence: float
    evidence: List[str] = field(default_factory=list)


@dataclass
class SyncResult:
    """Ù†ØªÙŠØ¬Ø© Ø§Ù„ØªØ²Ø§Ù…Ù†"""
    vision_concepts: List[VisualConcept]
    reasoning_concepts: List[ReasoningConcept]
    text_context: Optional[str]

    # Ø§Ù„ØªØ­Ù„ÙŠÙ„
    sync_status: SyncStatus
    alignment_score: float  # 0.0-1.0
    conflicts: List[str]
    resolved_concepts: List[str]

    # Ø§Ù„ØªÙˆØµÙŠØ§Øª
    recommendation: str
    confidence_adjustment: float  # ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ

    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    def to_dict(self) -> Dict[str, Any]:
        return {
            "vision_concepts": [
                {
                    "type": v.concept_type,
                    "label": v.label,
                    "confidence": v.confidence,
                    "attributes": v.attributes
                }
                for v in self.vision_concepts
            ],
            "reasoning_concepts": [
                {
                    "type": r.concept_type,
                    "label": r.label,
                    "confidence": r.confidence,
                    "evidence": r.evidence
                }
                for r in self.reasoning_concepts
            ],
            "text_context": self.text_context,
            "sync_status": self.sync_status.value,
            "alignment_score": self.alignment_score,
            "conflicts": self.conflicts,
            "resolved_concepts": self.resolved_concepts,
            "recommendation": self.recommendation,
            "confidence_adjustment": self.confidence_adjustment
        }


class VisionReasoningSynchronizer:
    """
    Ù…ÙˆØ­Ù‘Ø¯ Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªÙÙƒÙŠØ±

    ÙŠÙ‚ÙˆÙ… Ø¨Ù€:
    1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ø¨ØµØ±ÙŠØ© Ù…Ù† Ø§Ù„ØµÙˆØ± (via image_analyzer + OCR)
    2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ù…Ù†Ø·Ù‚ÙŠØ© Ù…Ù† Ø§Ù„Ù†ØµÙˆØµ (via NLP)
    3. Ù…Ù‚Ø§Ø±Ù†Ø© ÙˆÙ…ÙˆØ§Ø²Ù†Ø© Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
    4. ÙƒØ´Ù Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª
    5. Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª Ø£Ùˆ Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù†Ù‡Ø§
    """

    def __init__(self):
        self.project_root = "/home/noogh/projects/noogh_unified_system"

        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©
        self.vision_available = self._check_vision_systems()
        self.reasoning_available = self._check_reasoning_systems()
        self.nlp_available = self._check_nlp_systems()

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_syncs = 0
        self.conflicts_detected = 0
        self.conflicts_resolved = 0

    def _check_vision_systems(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø±Ø¤ÙŠØ©"""
        return (
            os.path.exists(f"{self.project_root}/core/vision/image_analyzer.py") and
            os.path.exists(f"{self.project_root}/core/vision/ocr_engine.py")
        )

    def _check_reasoning_systems(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªÙÙƒÙŠØ±"""
        return os.path.exists(f"{self.project_root}/core/reasoning")

    def _check_nlp_systems(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± Ø£Ù†Ø¸Ù…Ø© NLP"""
        return os.path.exists(f"{self.project_root}/core/nlp")

    def synchronize(self,
                   image_path: Optional[str] = None,
                   text_description: Optional[str] = None,
                   expected_labels: Optional[List[str]] = None) -> SyncResult:
        """
        ØªØ²Ø§Ù…Ù† Ø¨ÙŠÙ† Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªÙÙƒÙŠØ±

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            text_description: ÙˆØµÙ Ù†ØµÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            expected_labels: ØªØ³Ù…ÙŠØ§Øª Ù…ØªÙˆÙ‚Ø¹Ø© Ù„Ù„ØªØ­Ù‚Ù‚ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

        Returns:
            SyncResult
        """
        self.total_syncs += 1

        # 1. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ø¨ØµØ±ÙŠØ©
        vision_concepts = self._extract_visual_concepts(image_path) if image_path else []

        # 2. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ù…Ù†Ø·Ù‚ÙŠØ© Ù…Ù† Ø§Ù„Ù†Øµ
        reasoning_concepts = self._extract_reasoning_concepts(text_description) if text_description else []

        # 3. Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† expected_labels
        if expected_labels:
            label_concepts = [
                ReasoningConcept(
                    concept_type="entity",
                    label=label,
                    confidence=0.9,
                    evidence=["user_provided_label"]
                )
                for label in expected_labels
            ]
            reasoning_concepts.extend(label_concepts)

        # 4. Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ…
        alignment_score, conflicts = self._compare_concepts(vision_concepts, reasoning_concepts)

        # 5. ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ²Ø§Ù…Ù†
        sync_status = self._determine_sync_status(alignment_score, len(conflicts))

        # 6. Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª (Ø¥Ù† Ø£Ù…ÙƒÙ†)
        resolved_concepts, confidence_adjustment = self._resolve_conflicts(
            vision_concepts, reasoning_concepts, conflicts
        )

        if resolved_concepts:
            self.conflicts_resolved += len(resolved_concepts)

        if conflicts:
            self.conflicts_detected += len(conflicts)

        # 7. ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ©
        recommendation = self._generate_recommendation(sync_status, conflicts, resolved_concepts)

        return SyncResult(
            vision_concepts=vision_concepts,
            reasoning_concepts=reasoning_concepts,
            text_context=text_description,
            sync_status=sync_status,
            alignment_score=alignment_score,
            conflicts=conflicts,
            resolved_concepts=resolved_concepts,
            recommendation=recommendation,
            confidence_adjustment=confidence_adjustment
        )

    def _extract_visual_concepts(self, image_path: str) -> List[VisualConcept]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ù…Ù† ØµÙˆØ±Ø©"""
        if not self.vision_available:
            return []

        concepts = []

        try:
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Image Analyzer
            from vision.image_analyzer import ImageAnalyzer

            analyzer = ImageAnalyzer()
            result = analyzer.analyze_image(image_path)

            # ØªØ­ÙˆÙŠÙ„ Ù„Ù…ÙØ§Ù‡ÙŠÙ…
            # 1. Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©
            concepts.append(VisualConcept(
                concept_type="scene",
                label=result.image_type.value,
                confidence=0.8,
                attributes={
                    "dimensions": f"{result.dimensions.width}x{result.dimensions.height}",
                    "orientation": result.dimensions.orientation
                }
            ))

            # 2. Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù†
            concepts.append(VisualConcept(
                concept_type="pattern",
                label=f"color_scheme_{result.colors.color_scheme.value}",
                confidence=0.7,
                attributes={
                    "brightness": result.colors.brightness_avg,
                    "diversity": result.colors.color_diversity
                }
            ))

            # 3. Ø§Ù„Ù…Ø­ØªÙˆÙ‰
            if result.content.has_text:
                concepts.append(VisualConcept(
                    concept_type="text",
                    label="text_detected",
                    confidence=0.8 if result.content.text_density > 0.3 else 0.5
                ))

        except Exception as e:
            # ÙÙŠ Ø­Ø§Ù„Ø© ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            concepts.append(VisualConcept(
                concept_type="error",
                label=f"analysis_failed: {str(e)}",
                confidence=0.0
            ))

        # Ù…Ø­Ø§ÙˆÙ„Ø© OCR
        try:
            from vision.ocr_engine import OCREngine

            ocr = OCREngine()
            ocr_result = ocr.extract_text(image_path)

            if ocr_result.full_text.strip():
                concepts.append(VisualConcept(
                    concept_type="text",
                    label="ocr_extracted",
                    confidence=ocr_result.average_confidence,
                    attributes={
                        "text": ocr_result.full_text[:100],  # Ø£ÙˆÙ„ 100 Ø­Ø±Ù
                        "languages": ocr_result.detected_languages
                    }
                ))

        except Exception:
            pass

        return concepts

    def _extract_reasoning_concepts(self, text: str) -> List[ReasoningConcept]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙØ§Ù‡ÙŠÙ… Ù…Ù†Ø·Ù‚ÙŠØ© Ù…Ù† Ù†Øµ"""
        if not self.nlp_available:
            return []

        concepts = []

        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· (ÙÙŠ Ù†Ø¸Ø§Ù… ÙƒØ§Ù…Ù„ØŒ Ù†Ø³ØªØ®Ø¯Ù… NER + Dependency Parsing)
        text_lower = text.lower()

        # ÙƒØ´Ù ÙƒÙŠØ§Ù†Ø§Øª Ø¨Ø³ÙŠØ·
        entities = [
            ("dog", "animal"),
            ("cat", "animal"),
            ("car", "vehicle"),
            ("tree", "plant"),
            ("house", "building"),
            ("ÙƒÙ„Ø¨", "animal"),
            ("Ù‚Ø·Ø©", "animal"),
            ("Ø³ÙŠØ§Ø±Ø©", "vehicle")
        ]

        for entity, entity_type in entities:
            if entity in text_lower:
                concepts.append(ReasoningConcept(
                    concept_type="entity",
                    label=entity,
                    confidence=0.8,
                    evidence=[f"mentioned in text: '{entity}'"]
                ))

        # ÙƒØ´Ù Ø£ÙØ¹Ø§Ù„ (actions)
        actions = ["running", "walking", "sitting", "ÙŠØ±ÙƒØ¶", "ÙŠÙ…Ø´ÙŠ", "ÙŠØ¬Ù„Ø³"]
        for action in actions:
            if action in text_lower:
                concepts.append(ReasoningConcept(
                    concept_type="action",
                    label=action,
                    confidence=0.7,
                    evidence=[f"action detected: '{action}'"]
                ))

        return concepts

    def _compare_concepts(self,
                         vision: List[VisualConcept],
                         reasoning: List[ReasoningConcept]) -> Tuple[float, List[str]]:
        """
        Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ø¨ØµØ±ÙŠØ© ÙˆØ§Ù„Ù…Ù†Ø·Ù‚ÙŠØ©

        Returns:
            (alignment_score, conflicts)
        """
        if not vision and not reasoning:
            return 1.0, []

        if not vision or not reasoning:
            return 0.5, ["Partial data: only one modality available"]

        conflicts = []

        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ØªØ·Ø§Ø¨Ù‚
        vision_labels = set(v.label.lower() for v in vision)
        reasoning_labels = set(r.label.lower() for r in reasoning)

        # Ø­Ø³Ø§Ø¨ Jaccard similarity
        intersection = vision_labels & reasoning_labels
        union = vision_labels | reasoning_labels

        if union:
            alignment = len(intersection) / len(union)
        else:
            alignment = 0.0

        # ÙƒØ´Ù ØªØ¹Ø§Ø±Ø¶Ø§Øª ÙˆØ§Ø¶Ø­Ø©
        # Ù…Ø«Ø§Ù„: Ø§Ù„Ù†Øµ ÙŠÙ‚ÙˆÙ„ "dog" Ù„ÙƒÙ† Ø§Ù„ØµÙˆØ±Ø© ØªÙØ¸Ù‡Ø± "cat"
        contradictory_pairs = [
            ("dog", "cat"),
            ("ÙƒÙ„Ø¨", "Ù‚Ø·Ø©"),
            ("car", "bicycle"),
            ("day", "night")
        ]

        for v_concept in vision:
            for r_concept in reasoning:
                for pair in contradictory_pairs:
                    if (pair[0] in v_concept.label.lower() and pair[1] in r_concept.label.lower()) or \
                       (pair[1] in v_concept.label.lower() and pair[0] in r_concept.label.lower()):
                        conflicts.append(
                            f"Contradiction: Vision shows '{v_concept.label}' but text mentions '{r_concept.label}'"
                        )

        return alignment, conflicts

    def _determine_sync_status(self, alignment: float, conflict_count: int) -> SyncStatus:
        """ØªØ­Ø¯ÙŠØ¯ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ²Ø§Ù…Ù†"""
        if conflict_count > 0:
            if alignment < 0.3:
                return SyncStatus.MAJOR_CONFLICT
            else:
                return SyncStatus.PARTIAL_CONFLICT

        if alignment >= 0.7:
            return SyncStatus.ALIGNED
        else:
            return SyncStatus.UNSYNCHRONIZED

    def _resolve_conflicts(self,
                          vision: List[VisualConcept],
                          reasoning: List[ReasoningConcept],
                          conflicts: List[str]) -> Tuple[List[str], float]:
        """
        Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ù„ Ø§Ù„ØªØ¹Ø§Ø±Ø¶Ø§Øª

        Returns:
            (resolved_concepts, confidence_adjustment)
        """
        resolved = []
        confidence_adjustment = 1.0

        if not conflicts:
            return resolved, confidence_adjustment

        # Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ø­Ù„:
        # 1. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø«Ù‚Ø© Ø§Ù„Ø±Ø¤ÙŠØ© Ø£Ø¹Ù„Ù‰ØŒ Ù†ÙØ¶Ù„ Ø§Ù„Ø±Ø¤ÙŠØ©
        # 2. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø«Ù‚Ø© Ø§Ù„ØªÙÙƒÙŠØ± Ø£Ø¹Ù„Ù‰ØŒ Ù†ÙØ¶Ù„ Ø§Ù„ØªÙÙƒÙŠØ±
        # 3. Ø¥Ø°Ø§ Ù…ØªØ³Ø§ÙˆÙŠØ©ØŒ Ù†ÙØ®ÙÙ‘Ø¶ Ø§Ù„Ø«Ù‚Ø© ÙˆÙ†ÙØ¨Ù„Øº Ø¹Ù† Ø§Ù„ØªØ¹Ø§Ø±Ø¶

        for conflict in conflicts:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙØ§Ù‡ÙŠÙ… Ø§Ù„Ù…ØªØ¹Ø§Ø±Ø¶Ø©
            # (ÙÙŠ Ù†Ø¸Ø§Ù… Ø­Ù‚ÙŠÙ‚ÙŠØŒ parsing Ø£Ø¯Ù‚)
            if "Vision shows" in conflict and "text mentions" in conflict:
                # ØªØ®ÙÙŠØ¶ Ø§Ù„Ø«Ù‚Ø©
                confidence_adjustment *= 0.7
                resolved.append(f"Unresolved: {conflict} - confidence reduced")

        return resolved, confidence_adjustment

    def _generate_recommendation(self,
                                status: SyncStatus,
                                conflicts: List[str],
                                resolved: List[str]) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ©"""
        if status == SyncStatus.ALIGNED:
            return "Proceed - vision and reasoning are aligned"

        if status == SyncStatus.MAJOR_CONFLICT:
            return f"Do not proceed - major conflicts detected: {len(conflicts)} issue(s)"

        if status == SyncStatus.PARTIAL_CONFLICT:
            if resolved:
                return f"Proceed with caution - {len(resolved)} conflict(s) resolved"
            else:
                return f"Review required - {len(conflicts)} unresolved conflict(s)"

        return "Insufficient data - unable to synchronize modalities"

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
        return {
            "total_syncs": self.total_syncs,
            "conflicts_detected": self.conflicts_detected,
            "conflicts_resolved": self.conflicts_resolved,
            "resolution_rate": (self.conflicts_resolved / self.conflicts_detected * 100) if self.conflicts_detected > 0 else 0.0,
            "vision_available": self.vision_available,
            "reasoning_available": self.reasoning_available,
            "nlp_available": self.nlp_available
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Usage Example
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("ğŸ”— Vision-Reasoning Synchronizer - Test")
    print("=" * 70)
    print()

    sync = VisionReasoningSynchronizer()

    print(f"Vision Systems: {'âœ… Available' if sync.vision_available else 'âŒ Not available'}")
    print(f"Reasoning Systems: {'âœ… Available' if sync.reasoning_available else 'âŒ Not available'}")
    print(f"NLP Systems: {'âœ… Available' if sync.nlp_available else 'âŒ Not available'}")
    print()

    # Test Case: ØªØ²Ø§Ù…Ù† Ù†Øµ ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† ØµÙˆØ±Ø©)
    print("1ï¸âƒ£ Test: Text-only synchronization")
    print("-" * 70)

    result = sync.synchronize(
        text_description="A dog is running in the park",
        expected_labels=["dog", "park", "running"]
    )

    print(f"Sync Status: {result.sync_status.value}")
    print(f"Alignment Score: {result.alignment_score:.2f}")
    print(f"Reasoning Concepts: {len(result.reasoning_concepts)}")
    print(f"Conflicts: {len(result.conflicts)}")
    print(f"Recommendation: {result.recommendation}")
    print()

    # Test Case: ØªØ¹Ø§Ø±Ø¶
    print("2ï¸âƒ£ Test: Conflict detection")
    print("-" * 70)

    result2 = sync.synchronize(
        text_description="There is a cat sitting on the couch",
        expected_labels=["dog"]  # ØªØ¹Ø§Ø±Ø¶: Ø§Ù„Ù†Øµ ÙŠÙ‚ÙˆÙ„ catØŒ Ø§Ù„ØªØ³Ù…ÙŠØ© dog
    )

    print(f"Sync Status: {result2.sync_status.value}")
    print(f"Alignment Score: {result2.alignment_score:.2f}")
    print(f"Conflicts Detected: {len(result2.conflicts)}")
    if result2.conflicts:
        for conflict in result2.conflicts:
            print(f"  âš ï¸ {conflict}")
    print(f"Confidence Adjustment: {result2.confidence_adjustment:.2f}")
    print(f"Recommendation: {result2.recommendation}")
    print()

    print("=" * 70)
    stats = sync.get_statistics()
    print("ğŸ“Š Statistics:")
    for key, value in stats.items():
        print(f"  {key}: {value}")
    print()
    print("âœ… Vision-Reasoning Synchronizer Test Complete!")
    print()
