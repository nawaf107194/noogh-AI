"""
Confidence Measurement System - Ù†Ø¸Ø§Ù… Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø©
================================================

ÙŠÙ‚ÙŠØ³ Ø«Ù‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª Ø±Ù‚Ù…ÙŠØ§Ù‹ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø¹ÙˆØ§Ù…Ù„
"""

from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime, timezone
from enum import Enum
import statistics


class ConfidenceLevel(Enum):
    """Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø©"""
    VERY_LOW = "very_low"      # 0-20%
    LOW = "low"                 # 20-40%
    MODERATE = "moderate"       # 40-60%
    HIGH = "high"               # 60-80%
    VERY_HIGH = "very_high"     # 80-100%


@dataclass
class ConfidenceFactor:
    """Ø¹Ø§Ù…Ù„ ÙˆØ§Ø­Ø¯ ÙŠØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©"""
    name: str
    score: float  # 0.0 - 1.0
    weight: float  # Ø£Ù‡Ù…ÙŠØ© Ù‡Ø°Ø§ Ø§Ù„Ø¹Ø§Ù…Ù„
    evidence: str


@dataclass
class ConfidenceScore:
    """Ù†ØªÙŠØ¬Ø© Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø©"""
    overall_score: float  # 0.0 - 1.0
    level: ConfidenceLevel
    factors: List[ConfidenceFactor]
    timestamp: datetime
    reasoning: str


class ConfidenceScorer:
    """
    Ù†Ø¸Ø§Ù… Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ø´Ø§Ù…Ù„

    ÙŠÙ‚ÙŠØ³ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:
    1. Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±ÙŠØ©
    2. ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª
    3. Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¤ÙŠØ¯Ø©
    4. Ø§Ù„ØªØ£ÙƒÙŠØ¯Ø§Øª Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠØ©
    5. Ø³Ø¬Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
    6. ÙˆØ¶ÙˆØ­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    """

    def __init__(self):
        # Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø¹ÙˆØ§Ù…Ù„
        self.factor_weights = {
            "data_quality": 0.25,
            "consistency": 0.20,
            "source_count": 0.15,
            "internal_validation": 0.15,
            "past_performance": 0.15,
            "result_clarity": 0.10
        }

    def calculate_confidence(self,
                           decision: Dict[str, Any],
                           context: Optional[Dict[str, Any]] = None) -> ConfidenceScore:
        """
        Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© Ù‚Ø±Ø§Ø± Ù…Ø¹ÙŠÙ†

        Args:
            decision: Ø§Ù„Ù‚Ø±Ø§Ø± Ø£Ùˆ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
            context: Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¥Ø¶Ø§ÙÙŠ

        Returns:
            ConfidenceScore: Ù†ØªÙŠØ¬Ø© Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø©
        """
        context = context or {}
        factors = []

        # 1. Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        data_quality = self._assess_data_quality(decision, context)
        factors.append(ConfidenceFactor(
            name="data_quality",
            score=data_quality,
            weight=self.factor_weights["data_quality"],
            evidence=f"Data quality assessment: {data_quality:.2f}"
        ))

        # 2. ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª
        consistency = self._assess_consistency(decision, context)
        factors.append(ConfidenceFactor(
            name="consistency",
            score=consistency,
            weight=self.factor_weights["consistency"],
            evidence=f"Internal consistency: {consistency:.2f}"
        ))

        # 3. Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±
        source_score = self._assess_sources(decision, context)
        factors.append(ConfidenceFactor(
            name="source_count",
            score=source_score,
            weight=self.factor_weights["source_count"],
            evidence=f"Source reliability: {source_score:.2f}"
        ))

        # 4. Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ
        validation_score = self._assess_internal_validation(decision, context)
        factors.append(ConfidenceFactor(
            name="internal_validation",
            score=validation_score,
            weight=self.factor_weights["internal_validation"],
            evidence=f"Internal validation: {validation_score:.2f}"
        ))

        # 5. Ø³Ø¬Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
        performance_score = self._assess_past_performance(decision, context)
        factors.append(ConfidenceFactor(
            name="past_performance",
            score=performance_score,
            weight=self.factor_weights["past_performance"],
            evidence=f"Historical performance: {performance_score:.2f}"
        ))

        # 6. ÙˆØ¶ÙˆØ­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        clarity_score = self._assess_result_clarity(decision, context)
        factors.append(ConfidenceFactor(
            name="result_clarity",
            score=clarity_score,
            weight=self.factor_weights["result_clarity"],
            evidence=f"Result clarity: {clarity_score:.2f}"
        ))

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠØ©
        overall_score = sum(f.score * f.weight for f in factors)

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ø³ØªÙˆÙ‰
        level = self._determine_level(overall_score)

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØªÙØ³ÙŠØ±
        reasoning = self._generate_reasoning(factors, overall_score)

        return ConfidenceScore(
            overall_score=overall_score,
            level=level,
            factors=factors,
            timestamp=datetime.now(timezone.utc),
            reasoning=reasoning
        )

    def _assess_data_quality(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØµØ¯Ø±ÙŠØ©"""
        score = 0.5  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©

        # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ÙƒØ§ÙÙŠØ©
        if "sources" in decision:
            sources = decision["sources"]
            if isinstance(sources, list):
                # ÙƒÙ„Ù…Ø§ Ø²Ø§Ø¯Øª Ø§Ù„Ù…ØµØ§Ø¯Ø±ØŒ Ø²Ø§Ø¯Øª Ø§Ù„Ø«Ù‚Ø©
                score += min(0.3, len(sources) * 0.1)

        # ÙØ­Øµ Ø¬ÙˆØ¯Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
        if "input_quality" in context:
            score += context["input_quality"] * 0.2

        # ÙØ­Øµ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        if "data_completeness" in context:
            score += context["data_completeness"] * 0.2

        return min(1.0, score)

    def _assess_consistency(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬Ø§Øª"""
        score = 0.6  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©

        # ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ
        if "internal_consistency" in decision:
            score = decision["internal_consistency"]

        # ÙØ­Øµ Ø§Ù„ØªÙ†Ø§Ø³Ù‚ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚
        if "context_alignment" in context:
            score = (score + context["context_alignment"]) / 2

        # ÙØ­Øµ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ ØªÙ†Ø§Ù‚Ø¶Ø§Øª
        if "contradictions" in decision:
            contradictions = len(decision.get("contradictions", []))
            score -= min(0.4, contradictions * 0.1)

        return max(0.0, min(1.0, score))

    def _assess_sources(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ§Ø¯Ø±"""
        if "sources" not in decision:
            return 0.3  # Ù„Ø§ ØªÙˆØ¬Ø¯ Ù…ØµØ§Ø¯Ø±

        sources = decision["sources"]

        if not sources:
            return 0.3

        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…ØµØ§Ø¯Ø±
        source_count = len(sources) if isinstance(sources, list) else 1

        # Ù†Ù‚Ø§Ø· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¹Ø¯Ø¯
        if source_count >= 5:
            score = 1.0
        elif source_count >= 3:
            score = 0.8
        elif source_count >= 2:
            score = 0.6
        else:
            score = 0.4

        # ØªØ¹Ø¯ÙŠÙ„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ§Ø¯Ø±
        if "source_reliability" in context:
            reliability = context["source_reliability"]
            score = (score + reliability) / 2

        return score

    def _assess_internal_validation(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„ØªØ­Ù‚Ù‚ Ø§Ù„Ø¯Ø§Ø®Ù„ÙŠ"""
        score = 0.5

        # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ ØªØ­Ù‚Ù‚
        if "validated" in decision and decision["validated"]:
            score += 0.3

        # ÙØ­Øµ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù‚Ù‚
        if "validation_results" in decision:
            results = decision["validation_results"]
            if isinstance(results, dict):
                passed = results.get("passed", 0)
                total = results.get("total", 1)
                score += (passed / total) * 0.4

        return min(1.0, score)

    def _assess_past_performance(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚"""
        # Ø§Ù„Ù†Ø¸Ø± ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
        if "performance_history" in context:
            history = context["performance_history"]

            if isinstance(history, list) and history:
                # Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø³Ø§Ø¨Ù‚
                avg_performance = statistics.mean(history)
                return avg_performance

        # ÙØ­Øµ Ø¯Ù‚Ø© Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø´Ø§Ø¨Ù‡Ø©
        if "similar_decisions_accuracy" in context:
            return context["similar_decisions_accuracy"]

        return 0.5  # Ù‚ÙŠÙ…Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© (ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙ)

    def _assess_result_clarity(self, decision: Dict, context: Dict) -> float:
        """ØªÙ‚ÙŠÙŠÙ… ÙˆØ¶ÙˆØ­ Ø§Ù„Ù†ØªØ§Ø¦Ø¬"""
        score = 0.5

        # ÙØ­Øµ ÙˆØ¶ÙˆØ­ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
        if "result" in decision:
            result = decision["result"]

            # Ø·ÙˆÙ„ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
            if isinstance(result, str):
                length = len(result)
                if 10 <= length <= 500:
                    score += 0.2

        # ÙØ­Øµ Ø§Ù„ØºÙ…ÙˆØ¶
        if "ambiguity_score" in decision:
            ambiguity = decision["ambiguity_score"]
            score -= ambiguity * 0.3

        # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ ØªÙØ³ÙŠØ±
        if "explanation" in decision and decision["explanation"]:
            score += 0.2

        return max(0.0, min(1.0, score))

    def _determine_level(self, score: float) -> ConfidenceLevel:
        """ØªØ­Ø¯ÙŠØ¯ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù†Ù‚Ø§Ø·"""
        if score >= 0.8:
            return ConfidenceLevel.VERY_HIGH
        elif score >= 0.6:
            return ConfidenceLevel.HIGH
        elif score >= 0.4:
            return ConfidenceLevel.MODERATE
        elif score >= 0.2:
            return ConfidenceLevel.LOW
        else:
            return ConfidenceLevel.VERY_LOW

    def _generate_reasoning(self, factors: List[ConfidenceFactor], overall_score: float) -> str:
        """ØªÙˆÙ„ÙŠØ¯ ØªÙØ³ÙŠØ± Ù„Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        # Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø£Ù‚ÙˆÙ‰
        sorted_factors = sorted(factors, key=lambda f: f.score * f.weight, reverse=True)

        reasoning_parts = [
            f"Overall confidence: {overall_score*100:.1f}%"
        ]

        # Ø£ÙØ¶Ù„ 3 Ø¹ÙˆØ§Ù…Ù„
        reasoning_parts.append("Strongest factors:")
        for factor in sorted_factors[:3]:
            reasoning_parts.append(f"  â€¢ {factor.name}: {factor.score*100:.1f}%")

        # Ø£Ø¶Ø¹Ù Ø¹Ø§Ù…Ù„
        weakest = sorted_factors[-1]
        if weakest.score < 0.4:
            reasoning_parts.append(f"Weakest factor: {weakest.name} ({weakest.score*100:.1f}%)")

        return "\n".join(reasoning_parts)

    def should_proceed_with_decision(self, confidence: ConfidenceScore,
                                    min_threshold: float = 0.5) -> Tuple[bool, str]:
        """
        Ù‡Ù„ ÙŠØ¬Ø¨ Ø§Ù„Ù…Ø¶ÙŠ Ù‚Ø¯Ù…Ø§Ù‹ Ø¨Ø§Ù„Ù‚Ø±Ø§Ø±ØŸ

        Returns:
            (should_proceed, reason)
        """
        if confidence.overall_score >= min_threshold:
            return True, f"Confidence {confidence.overall_score*100:.1f}% meets threshold"

        # ÙØ­Øµ Ø§Ù„Ø¹ÙˆØ§Ù…Ù„ Ø§Ù„Ø­Ø±Ø¬Ø©
        critical_factors = ["data_quality", "consistency", "internal_validation"]

        low_critical_factors = [
            f.name for f in confidence.factors
            if f.name in critical_factors and f.score < 0.4
        ]

        if low_critical_factors:
            return False, f"Critical factors too low: {', '.join(low_critical_factors)}"

        return False, f"Overall confidence {confidence.overall_score*100:.1f}% below threshold"


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Usage Example
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”


if __name__ == "__main__":
    print("ğŸ“Š Confidence Measurement System - Test")
    print("=" * 70)

    scorer = ConfidenceScorer()

    # Ù…Ø«Ø§Ù„ 1: Ù‚Ø±Ø§Ø± Ø¨Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
    print("\n1ï¸âƒ£ High confidence decision:")
    decision1 = {
        "result": "Paris is the capital of France",
        "sources": ["encyclopedia", "wikipedia", "official_source"],
        "validated": True,
        "validation_results": {"passed": 5, "total": 5}
    }

    context1 = {
        "input_quality": 0.9,
        "data_completeness": 0.95,
        "source_reliability": 0.9,
        "performance_history": [0.92, 0.89, 0.91]
    }

    confidence1 = scorer.calculate_confidence(decision1, context1)
    print(f"   Score: {confidence1.overall_score*100:.1f}%")
    print(f"   Level: {confidence1.level.value}")
    print(f"   {confidence1.reasoning}")

    should_proceed, reason = scorer.should_proceed_with_decision(confidence1)
    print(f"   Proceed: {should_proceed} - {reason}")

    # Ù…Ø«Ø§Ù„ 2: Ù‚Ø±Ø§Ø± Ø¨Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø©
    print("\n2ï¸âƒ£ Low confidence decision:")
    decision2 = {
        "result": "The answer is unclear",
        "sources": [],
        "validated": False,
        "contradictions": ["conflict1", "conflict2"]
    }

    context2 = {
        "input_quality": 0.3,
        "data_completeness": 0.4
    }

    confidence2 = scorer.calculate_confidence(decision2, context2)
    print(f"   Score: {confidence2.overall_score*100:.1f}%")
    print(f"   Level: {confidence2.level.value}")
    print(f"   {confidence2.reasoning}")

    should_proceed, reason = scorer.should_proceed_with_decision(confidence2)
    print(f"   Proceed: {should_proceed} - {reason}")

    print("\n" + "=" * 70)
