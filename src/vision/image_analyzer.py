"""
Image Analyzer - Ù…Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±
=============================

ÙŠØ­Ù„Ù„ Ø§Ù„ØµÙˆØ± ÙˆÙŠØ³ØªØ®Ø±Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© (Ø§Ù„Ø£Ù„ÙˆØ§Ù†ØŒ Ø§Ù„Ø£Ø´ÙƒØ§Ù„ØŒ Ø§Ù„ØªÙƒÙˆÙŠÙ†ØŒ Ø¥Ù„Ø®)

Addresses Computer Vision capabilities from Self-Audit

Author: Noogh AI Team
Date: 2025-11-10
Priority: HIGH
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
import os
import hashlib


class ImageType(str, Enum):
    """Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©"""
    PHOTO = "photo"
    DIAGRAM = "diagram"
    SCREENSHOT = "screenshot"
    DOCUMENT = "document"
    ARTWORK = "artwork"
    UNKNOWN = "unknown"


class ColorScheme(str, Enum):
    """Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù†"""
    GRAYSCALE = "grayscale"
    MONOCHROME = "monochrome"
    COLORFUL = "colorful"
    PASTEL = "pastel"
    VIBRANT = "vibrant"
    DARK = "dark"
    LIGHT = "light"


@dataclass
class ColorInfo:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ù„ÙˆØ§Ù†"""
    dominant_colors: List[Tuple[int, int, int]]  # RGB tuples
    color_scheme: ColorScheme
    color_diversity: float  # 0.0-1.0
    brightness_avg: float  # 0-255


@dataclass
class DimensionInfo:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯"""
    width: int
    height: int
    aspect_ratio: float
    megapixels: float
    orientation: str  # "landscape", "portrait", "square"


@dataclass
class ContentAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
    has_text: bool
    text_density: float  # 0.0-1.0
    estimated_complexity: float  # 0.0-1.0 (Ø¨Ø³ÙŠØ· â†’ Ù…Ø¹Ù‚Ø¯)
    edges_detected: int
    regions_count: int


@dataclass
class ImageAnalysisResult:
    """Ù†ØªÙŠØ¬Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©"""
    image_path: str
    file_size_bytes: int
    image_type: ImageType
    dimensions: DimensionInfo
    colors: ColorInfo
    content: ContentAnalysis
    file_hash: str
    timestamp: datetime

    def to_dict(self) -> Dict[str, Any]:
        return {
            "image_path": self.image_path,
            "file_size_mb": self.file_size_bytes / (1024 * 1024),
            "image_type": self.image_type.value,
            "dimensions": {
                "width": self.dimensions.width,
                "height": self.dimensions.height,
                "aspect_ratio": self.dimensions.aspect_ratio,
                "megapixels": self.dimensions.megapixels,
                "orientation": self.dimensions.orientation
            },
            "colors": {
                "dominant_colors": self.colors.dominant_colors,
                "color_scheme": self.colors.color_scheme.value,
                "color_diversity": self.colors.color_diversity,
                "brightness": self.colors.brightness_avg
            },
            "content": {
                "has_text": self.content.has_text,
                "text_density": self.content.text_density,
                "complexity": self.content.estimated_complexity,
                "edges": self.content.edges_detected,
                "regions": self.content.regions_count
            },
            "file_hash": self.file_hash,
            "timestamp": self.timestamp.isoformat()
        }


class ImageAnalyzer:
    """
    Ù…Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±

    ÙŠØ­Ù„Ù„:
    1. Ø£Ø¨Ø¹Ø§Ø¯ ÙˆÙ†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©
    2. Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø³Ø§Ø¦Ø¯Ø© ÙˆØ§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù„ÙˆÙ†ÙŠ
    3. Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙˆØ±Ø© (Ù†ØµÙˆØµØŒ ØªØ¹Ù‚ÙŠØ¯ØŒ Ø¥Ù„Ø®)
    4. Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
    """

    def __init__(self):
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ PIL/Pillow
        self.pil_available = self._check_pil()

        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ OpenCV
        self.opencv_available = self._check_opencv()

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_analyzed = 0
        self.analysis_history: List[ImageAnalysisResult] = []

    def _check_pil(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± PIL/Pillow"""
        try:
            from PIL import Image
            return True
        except Exception as e:
            return False

    def _check_opencv(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± OpenCV"""
        try:
            import cv2
            return True
        except Exception as e:
            return False

    def analyze_image(self, image_path: str) -> ImageAnalysisResult:
        """
        ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø© ÙƒØ§Ù…Ù„

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            ImageAnalysisResult
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù„Ù
        file_size = os.path.getsize(image_path)
        file_hash = self._compute_hash(image_path)

        if self.pil_available:
            result = self._analyze_with_pil(image_path, file_size, file_hash)
        else:
            result = self._analyze_basic(image_path, file_size, file_hash)

        self.total_analyzed += 1
        self.analysis_history.append(result)

        return result

    def _analyze_with_pil(self,
                         image_path: str,
                         file_size: int,
                         file_hash: str) -> ImageAnalysisResult:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PIL/Pillow"""
        from PIL import Image
        import numpy as np

        # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(image_path)

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        width, height = image.size
        aspect_ratio = width / height if height > 0 else 1.0
        megapixels = (width * height) / 1_000_000

        if aspect_ratio > 1.2:
            orientation = "landscape"
        elif aspect_ratio < 0.8:
            orientation = "portrait"
        else:
            orientation = "square"

        dimensions = DimensionInfo(
            width=width,
            height=height,
            aspect_ratio=aspect_ratio,
            megapixels=megapixels,
            orientation=orientation
        )

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        colors = self._analyze_colors_pil(image)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
        content = self._analyze_content_pil(image)

        # ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©
        image_type = self._determine_image_type(colors, content)

        return ImageAnalysisResult(
            image_path=image_path,
            file_size_bytes=file_size,
            image_type=image_type,
            dimensions=dimensions,
            colors=colors,
            content=content,
            file_hash=file_hash,
            timestamp=datetime.now(timezone.utc)
        )

    def _analyze_colors_pil(self, image) -> ColorInfo:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PIL"""
        from PIL import Image
        import numpy as np

        # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ RGB
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # ØªØµØºÙŠØ± Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„ØªØ­Ù„ÙŠÙ„
        small_image = image.resize((100, 100))
        pixels = np.array(small_image)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ø³Ø§Ø¦Ø¯Ø© (ØªØ¨Ø³ÙŠØ·)
        # ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… k-means clustering
        avg_color = pixels.mean(axis=(0, 1)).astype(int)
        dominant_colors = [tuple(avg_color)]

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø³Ø·ÙˆØ¹ Ø§Ù„Ù…ØªÙˆØ³Ø·
        brightness_avg = float(np.mean(pixels))

        # Ø­Ø³Ø§Ø¨ ØªÙ†ÙˆØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        color_std = float(np.std(pixels))
        color_diversity = min(color_std / 128.0, 1.0)  # Ù†Ø³Ø¨Ø© Ù…Ù† Ø§Ù„Ø§Ù†Ø­Ø±Ø§Ù Ø§Ù„Ù…Ø¹ÙŠØ§Ø±ÙŠ

        # ØªØ­Ø¯ÙŠØ¯ Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù†
        if color_diversity < 0.1:
            color_scheme = ColorScheme.MONOCHROME
        elif brightness_avg < 85:
            color_scheme = ColorScheme.DARK
        elif brightness_avg > 170:
            color_scheme = ColorScheme.LIGHT
        elif color_diversity > 0.5:
            color_scheme = ColorScheme.VIBRANT
        else:
            color_scheme = ColorScheme.COLORFUL

        return ColorInfo(
            dominant_colors=dominant_colors,
            color_scheme=color_scheme,
            color_diversity=color_diversity,
            brightness_avg=brightness_avg
        )

    def _analyze_content_pil(self, image) -> ContentAnalysis:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PIL"""
        import numpy as np

        # ØªØ­ÙˆÙŠÙ„ Ù„Ù€ grayscale
        gray_image = image.convert('L')
        gray_array = np.array(gray_image)

        # ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù (ØªØ¨Ø³ÙŠØ· - ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… Sobel/Canny)
        edges = self._simple_edge_detection(gray_array)
        edges_count = int(np.sum(edges > 0))

        # ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ù…Ù† Ø¹Ø¯Ø¯ Ø§Ù„Ø­ÙˆØ§Ù
        total_pixels = gray_array.size
        edge_ratio = edges_count / total_pixels
        estimated_complexity = min(edge_ratio * 10, 1.0)  # Ù†Ø³Ø¨Ø© ØªÙ‚Ø±ÙŠØ¨ÙŠØ©

        # ÙƒØ´Ù Ø§Ù„Ù†ØµÙˆØµ (ØªØ¨Ø³ÙŠØ·)
        # ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„: Ø§Ø³ØªØ®Ø¯Ø§Ù… OCR Ù„Ù„ÙƒØ´Ù Ø¹Ù† ÙˆØ¬ÙˆØ¯ Ù†ØµÙˆØµ
        variance = float(np.var(gray_array))
        has_text = variance > 1000  # Ù†ØµÙˆØµ Ø¹Ø§Ø¯Ø© ØªØ¹Ø·ÙŠ variance Ø¹Ø§Ù„ÙŠ

        text_density = 0.0  # placeholder - ÙŠØ­ØªØ§Ø¬ OCR Ù„Ù„Ø¯Ù‚Ø©

        # Ø¹Ø¯Ø¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ (ØªØ¨Ø³ÙŠØ·)
        regions_count = max(1, int(estimated_complexity * 10))

        return ContentAnalysis(
            has_text=has_text,
            text_density=text_density,
            estimated_complexity=estimated_complexity,
            edges_detected=edges_count,
            regions_count=regions_count
        )

    def _simple_edge_detection(self, gray_array) -> 'np.ndarray':
        """ÙƒØ´Ù Ø­ÙˆØ§Ù Ø¨Ø³ÙŠØ·"""
        import numpy as np

        # Sobel filter Ø¨Ø³ÙŠØ·
        kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]])
        kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]])

        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ÙÙ„ØªØ± (ØªØ¨Ø³ÙŠØ· - Ø¨Ø¯ÙˆÙ† padding)
        height, width = gray_array.shape
        edges = np.zeros((height - 2, width - 2))

        for i in range(1, height - 1):
            for j in range(1, width - 1):
                region = gray_array[i-1:i+2, j-1:j+2]
                gx = np.sum(region * kernel_x)
                gy = np.sum(region * kernel_y)
                edges[i-1, j-1] = np.sqrt(gx**2 + gy**2)

        # threshold
        threshold = 100
        edges = (edges > threshold).astype(np.uint8) * 255

        return edges

    def _determine_image_type(self, colors: ColorInfo, content: ContentAnalysis) -> ImageType:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„ØµÙˆØ±Ø©"""
        # Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø©
        if content.has_text and content.text_density > 0.3:
            return ImageType.DOCUMENT

        if colors.color_scheme in [ColorScheme.MONOCHROME, ColorScheme.GRAYSCALE] and content.has_text:
            return ImageType.SCREENSHOT

        if content.estimated_complexity < 0.2:
            return ImageType.DIAGRAM

        if colors.color_scheme == ColorScheme.VIBRANT and content.estimated_complexity > 0.5:
            return ImageType.ARTWORK

        return ImageType.PHOTO

    def _analyze_basic(self,
                      image_path: str,
                      file_size: int,
                      file_hash: str) -> ImageAnalysisResult:
        """ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· (fallback Ø¨Ø¯ÙˆÙ† PIL)"""
        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø£Ø³Ø§Ø³ÙŠØ© ÙÙ‚Ø·
        return ImageAnalysisResult(
            image_path=image_path,
            file_size_bytes=file_size,
            image_type=ImageType.UNKNOWN,
            dimensions=DimensionInfo(
                width=0,
                height=0,
                aspect_ratio=1.0,
                megapixels=0.0,
                orientation="unknown"
            ),
            colors=ColorInfo(
                dominant_colors=[(128, 128, 128)],
                color_scheme=ColorScheme.COLORFUL,
                color_diversity=0.5,
                brightness_avg=128.0
            ),
            content=ContentAnalysis(
                has_text=False,
                text_density=0.0,
                estimated_complexity=0.5,
                edges_detected=0,
                regions_count=1
            ),
            file_hash=file_hash,
            timestamp=datetime.now(timezone.utc)
        )

    def _compute_hash(self, file_path: str) -> str:
        """Ø­Ø³Ø§Ø¨ hash Ù„Ù„Ù…Ù„Ù"""
        hasher = hashlib.md5()
        with open(file_path, 'rb') as f:
            # Ù‚Ø±Ø§Ø¡Ø© Ø¹Ù„Ù‰ Ø¯ÙØ¹Ø§Øª Ù„Ù…Ù„ÙØ§Øª ÙƒØ¨ÙŠØ±Ø©
            for chunk in iter(lambda: f.read(4096), b""):
                hasher.update(chunk)
        return hasher.hexdigest()

    def compare_images(self, image_path1: str, image_path2: str) -> Dict[str, Any]:
        """
        Ù…Ù‚Ø§Ø±Ù†Ø© ØµÙˆØ±ØªÙŠÙ†

        Returns:
            ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§Ø±Ù†Ø©
        """
        analysis1 = self.analyze_image(image_path1)
        analysis2 = self.analyze_image(image_path2)

        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ù‡Ø§Ø´ (ØªØ·Ø§Ø¨Ù‚ ØªØ§Ù…)
        identical = analysis1.file_hash == analysis2.file_hash

        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯
        same_dimensions = (
            analysis1.dimensions.width == analysis2.dimensions.width and
            analysis1.dimensions.height == analysis2.dimensions.height
        )

        # Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† (ØªØ´Ø§Ø¨Ù‡ ØªÙ‚Ø±ÙŠØ¨ÙŠ)
        color_similarity = 1.0 - abs(
            analysis1.colors.color_diversity - analysis2.colors.color_diversity
        )

        return {
            "identical": identical,
            "same_dimensions": same_dimensions,
            "color_similarity": color_similarity,
            "type_match": analysis1.image_type == analysis2.image_type,
            "image1": analysis1.to_dict(),
            "image2": analysis2.to_dict()
        }

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ù„Ù„"""
        if self.total_analyzed == 0:
            return {
                "status": "no_data",
                "pil_available": self.pil_available,
                "opencv_available": self.opencv_available
            }

        return {
            "total_analyzed": self.total_analyzed,
            "pil_available": self.pil_available,
            "opencv_available": self.opencv_available,
            "image_types": {
                image_type.value: sum(
                    1 for r in self.analysis_history
                    if r.image_type == image_type
                )
                for image_type in ImageType
            }
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Usage Example
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("ğŸ–¼ï¸  Image Analyzer - Test")
    print("=" * 70)

    analyzer = ImageAnalyzer()

    print(f"PIL available: {analyzer.pil_available}")
    print(f"OpenCV available: {analyzer.opencv_available}")
    print()

    # ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ:
    # result = analyzer.analyze_image("path/to/image.png")
    # print(result.to_dict())

    print("=" * 70)
    print("ğŸ“Š Statistics:")
    stats = analyzer.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    print()

    print("âœ… Image Analyzer initialized successfully!")
    print("   To use: result = analyzer.analyze_image('image.png')")
    print()
