"""
Scene Understanding Enhancement - ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨ØµØ±ÙŠ Ø§Ù„Ù…Ø­Ø³Ù‘Ù†
=============================================================

ÙŠÙˆØ³Ù‘Ø¹ ImageAnalyzer Ø¨Ù‚Ø¯Ø±Ø§Øª ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ ÙˆØ§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©

Part of Deep Cognition v1.2 Lite - Scene Understanding
Addresses Q7 (Scene context interpretation)

Author: Noogh AI Team
Date: 2025-11-10
Priority: HIGH
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
import os

# Ø§Ø³ØªÙŠØ±Ø§Ø¯ ImageAnalyzer Ø§Ù„Ø­Ø§Ù„ÙŠ
try:
    from vision.image_analyzer import (
        ImageAnalyzer,
        ImageAnalysisResult,
        ImageType,
        ColorScheme
    )
    IMAGE_ANALYZER_AVAILABLE = True
except Exception as e:
    # Error caught: {e}
    IMAGE_ANALYZER_AVAILABLE = False


class SceneType(str, Enum):
    """Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù…ÙØ­Ø³Ù‘Ù†Ø©"""
    INDOOR = "indoor"
    OUTDOOR = "outdoor"
    URBAN = "urban"
    NATURE = "nature"
    WORKSPACE = "workspace"
    SOCIAL = "social"
    TRANSPORTATION = "transportation"
    UNKNOWN = "unknown"


class SpatialRelation(str, Enum):
    """Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©"""
    ABOVE = "above"
    BELOW = "below"
    LEFT_OF = "left_of"
    RIGHT_OF = "right_of"
    INSIDE = "inside"
    OUTSIDE = "outside"
    NEAR = "near"
    FAR = "far"
    CENTERED = "centered"


class LightingCondition(str, Enum):
    """Ø¸Ø±ÙˆÙ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø©"""
    BRIGHT = "bright"
    DIM = "dim"
    NATURAL_DAYLIGHT = "natural_daylight"
    ARTIFICIAL = "artificial"
    MIXED = "mixed"
    BACKLIT = "backlit"
    DARK = "dark"


@dataclass
class SpatialHint:
    """ØªÙ„Ù…ÙŠØ­ Ù…ÙƒØ§Ù†ÙŠ"""
    region: str  # "top", "bottom", "center", etc.
    density: float  # 0.0-1.0 (ÙƒØ«Ø§ÙØ© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ ÙÙŠ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©)
    dominant_feature: str  # Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø³Ø§Ø¦Ø¯Ø©


@dataclass
class SceneContext:
    """Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø´Ù‡Ø¯"""
    scene_type: SceneType
    lighting_condition: LightingCondition
    time_of_day_hint: Optional[str]  # "morning", "noon", "evening", "night"
    weather_hint: Optional[str]  # "sunny", "cloudy", "rainy" (Ù…Ù† Ø§Ù„Ø£Ù„ÙˆØ§Ù†)
    spatial_layout: Dict[str, SpatialHint]
    contextual_clues: List[str]  # Ù‚Ø±Ø§Ø¦Ù† Ø³ÙŠØ§Ù‚ÙŠØ© Ù…Ø³ØªÙ†ØªØ¬Ø©
    confidence: float  # 0.0-1.0


@dataclass
class EnhancedSceneAnalysis:
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø­Ø³Ù‘Ù† Ù„Ù„Ù…Ø´Ù‡Ø¯"""
    basic_analysis: Any  # ImageAnalysisResult from ImageAnalyzer
    scene_context: SceneContext
    complexity_score: float  # 0.0-1.0
    interpretability: float  # Ù…Ø¯Ù‰ Ø³Ù‡ÙˆÙ„Ø© ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø´Ù‡Ø¯
    timestamp: datetime = field(default_factory=lambda: datetime.now(timezone.utc))

    def to_dict(self) -> Dict[str, Any]:
        return {
            "scene_type": self.scene_context.scene_type.value,
            "lighting": self.scene_context.lighting_condition.value,
            "time_hint": self.scene_context.time_of_day_hint,
            "weather_hint": self.scene_context.weather_hint,
            "contextual_clues": self.scene_context.contextual_clues,
            "complexity": self.complexity_score,
            "interpretability": self.interpretability,
            "confidence": self.scene_context.confidence,
            "timestamp": self.timestamp.isoformat()
        }


class SceneUnderstandingEngine:
    """
    Ù…Ø­Ø±Ùƒ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¨ØµØ±ÙŠ

    ÙŠÙˆØ³Ù‘Ø¹ ImageAnalyzer Ø¨Ù‚Ø¯Ø±Ø§Øª:
    1. ØªØµÙ†ÙŠÙ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯ (indoor/outdoor/urban/nature)
    2. ØªØ­Ù„ÙŠÙ„ Ø¸Ø±ÙˆÙ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© (bright/dim/natural)
    3. Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„ÙˆÙ‚Øª Ù…Ù† Ø§Ù„ÙŠÙˆÙ… (morning/evening/night)
    4. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ø§Ù‚Ø§Øª Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ©
    5. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø±Ø§Ø¦Ù† Ø³ÙŠØ§Ù‚ÙŠØ©
    """

    def __init__(self):
        # ØªØ­Ù…ÙŠÙ„ ImageAnalyzer Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
        self.image_analyzer = ImageAnalyzer() if IMAGE_ANALYZER_AVAILABLE else None

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_analyzed = 0
        self.scene_type_counts: Dict[SceneType, int] = {}

    def analyze_scene(self, image_path: str) -> EnhancedSceneAnalysis:
        """
        ØªØ­Ù„ÙŠÙ„ Ù…Ø´Ù‡Ø¯ Ø´Ø§Ù…Ù„

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©

        Returns:
            EnhancedSceneAnalysis
        """
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")

        # ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠ Ù…Ù† ImageAnalyzer
        basic_analysis = None
        if self.image_analyzer:
            basic_analysis = self.image_analyzer.analyze_image(image_path)

        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
        scene_context = self._analyze_context(basic_analysis) if basic_analysis else self._fallback_context()

        # Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ ÙˆØ§Ù„Ù‚Ø§Ø¨Ù„ÙŠØ© Ù„Ù„ØªÙØ³ÙŠØ±
        complexity = self._calculate_complexity(basic_analysis) if basic_analysis else 0.5
        interpretability = self._calculate_interpretability(scene_context, complexity)

        result = EnhancedSceneAnalysis(
            basic_analysis=basic_analysis,
            scene_context=scene_context,
            complexity_score=complexity,
            interpretability=interpretability
        )

        self.total_analyzed += 1
        self.scene_type_counts[scene_context.scene_type] = \
            self.scene_type_counts.get(scene_context.scene_type, 0) + 1

        return result

    def _analyze_context(self, basic: 'ImageAnalysisResult') -> SceneContext:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚ Ù…Ù† Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©"""

        # 1. ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯
        scene_type = self._determine_scene_type(basic)

        # 2. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø©
        lighting = self._analyze_lighting(basic)

        # 3. Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„ÙˆÙ‚Øª Ù…Ù† Ø§Ù„ÙŠÙˆÙ…
        time_hint = self._infer_time_of_day(basic, lighting)

        # 4. Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø·Ù‚Ø³
        weather_hint = self._infer_weather(basic)

        # 5. ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ
        spatial_layout = self._analyze_spatial_layout(basic)

        # 6. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø±Ø§Ø¦Ù† Ø³ÙŠØ§Ù‚ÙŠØ©
        clues = self._extract_contextual_clues(
            scene_type, lighting, time_hint, weather_hint, spatial_layout
        )

        # 7. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
        confidence = self._calculate_context_confidence(basic, scene_type, lighting)

        return SceneContext(
            scene_type=scene_type,
            lighting_condition=lighting,
            time_of_day_hint=time_hint,
            weather_hint=weather_hint,
            spatial_layout=spatial_layout,
            contextual_clues=clues,
            confidence=confidence
        )

    def _determine_scene_type(self, basic: 'ImageAnalysisResult') -> SceneType:
        """ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        # Ù‚ÙˆØ§Ø¹Ø¯ Ø¨Ø³ÙŠØ·Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ø§Ù„ØµÙˆØ±Ø©

        image_type = basic.image_type
        color_scheme = basic.colors.color_scheme
        brightness = basic.colors.brightness_avg
        complexity = basic.content.estimated_complexity

        # DOCUMENT/SCREENSHOT â†’ WORKSPACE
        if image_type in ["document", "screenshot"]:
            return SceneType.WORKSPACE

        # DIAGRAM â†’ WORKSPACE
        if image_type == "diagram":
            return SceneType.WORKSPACE

        # Ø£Ù„ÙˆØ§Ù† Ø²Ø§Ù‡ÙŠØ© + ØªØ¹Ù‚ÙŠØ¯ Ø¹Ø§Ù„ÙŠ â†’ OUTDOOR/NATURE
        if color_scheme == "vibrant" and complexity > 0.6:
            # Ø³Ø·ÙˆØ¹ Ø¹Ø§Ù„ÙŠ â†’ OUTDOOR
            if brightness > 150:
                return SceneType.OUTDOOR
            else:
                return SceneType.NATURE

        # Ø£Ù„ÙˆØ§Ù† Ø¯Ø§ÙƒÙ†Ø© â†’ INDOOR
        if color_scheme == "dark" or brightness < 100:
            return SceneType.INDOOR

        # PHOTO Ù…Ø¹ ØªØ¹Ù‚ÙŠØ¯ Ù…ØªÙˆØ³Ø· â†’ SOCIAL
        if image_type == "photo" and 0.3 < complexity < 0.6:
            return SceneType.SOCIAL

        # Ø§ÙØªØ±Ø§Ø¶ÙŠ
        return SceneType.UNKNOWN

    def _analyze_lighting(self, basic: 'ImageAnalysisResult') -> LightingCondition:
        """ØªØ­Ù„ÙŠÙ„ Ø¸Ø±ÙˆÙ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø©"""
        brightness = basic.colors.brightness_avg
        color_diversity = basic.colors.color_diversity

        # Ø³Ø·ÙˆØ¹ Ø¹Ø§Ù„ÙŠ Ø¬Ø¯Ø§Ù‹ â†’ BRIGHT
        if brightness > 200:
            return LightingCondition.BRIGHT

        # Ø³Ø·ÙˆØ¹ Ù…Ù†Ø®ÙØ¶ â†’ DIM Ø£Ùˆ DARK
        if brightness < 80:
            return LightingCondition.DARK
        elif brightness < 120:
            return LightingCondition.DIM

        # ØªÙ†ÙˆØ¹ Ø£Ù„ÙˆØ§Ù† Ø¹Ø§Ù„ÙŠ + Ø³Ø·ÙˆØ¹ Ù…ØªÙˆØ³Ø· â†’ NATURAL_DAYLIGHT
        if color_diversity > 0.4 and 120 < brightness < 180:
            return LightingCondition.NATURAL_DAYLIGHT

        # Ø³Ø·ÙˆØ¹ Ù…ØªÙˆØ³Ø· + ØªÙ†ÙˆØ¹ Ù…Ù†Ø®ÙØ¶ â†’ ARTIFICIAL
        if color_diversity < 0.3 and 100 < brightness < 160:
            return LightingCondition.ARTIFICIAL

        # Ø§Ù„Ø¨Ø§Ù‚ÙŠ â†’ MIXED
        return LightingCondition.MIXED

    def _infer_time_of_day(self, basic: 'ImageAnalysisResult',
                          lighting: LightingCondition) -> Optional[str]:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„ÙˆÙ‚Øª Ù…Ù† Ø§Ù„ÙŠÙˆÙ…"""
        brightness = basic.colors.brightness_avg

        # BRIGHT + NATURAL â†’ NOON
        if lighting == LightingCondition.NATURAL_DAYLIGHT and brightness > 180:
            return "noon"

        # NATURAL + Ù…ØªÙˆØ³Ø· â†’ MORNING Ø£Ùˆ AFTERNOON
        if lighting == LightingCondition.NATURAL_DAYLIGHT:
            return "morning" if brightness < 150 else "afternoon"

        # DIM/DARK â†’ EVENING Ø£Ùˆ NIGHT
        if lighting in [LightingCondition.DIM, LightingCondition.DARK]:
            return "evening" if brightness > 60 else "night"

        return None

    def _infer_weather(self, basic: 'ImageAnalysisResult') -> Optional[str]:
        """Ø§Ø³ØªÙ†ØªØ§Ø¬ Ø§Ù„Ø·Ù‚Ø³ Ù…Ù† Ø§Ù„Ø£Ù„ÙˆØ§Ù†"""
        color_scheme = basic.colors.color_scheme
        brightness = basic.colors.brightness_avg

        # VIBRANT + BRIGHT â†’ SUNNY
        if color_scheme == "vibrant" and brightness > 170:
            return "sunny"

        # LIGHT + ØªÙ†ÙˆØ¹ Ù…Ù†Ø®ÙØ¶ â†’ CLOUDY
        if color_scheme == "light" and basic.colors.color_diversity < 0.3:
            return "cloudy"

        # DARK + Ø³Ø·ÙˆØ¹ Ù…Ù†Ø®ÙØ¶ â†’ RAINY
        if color_scheme == "dark" and brightness < 100:
            return "rainy"

        return None

    def _analyze_spatial_layout(self, basic: 'ImageAnalysisResult') -> Dict[str, SpatialHint]:
        """ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ (ØªØ¨Ø³ÙŠØ·)"""
        # ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„ÙƒØ§Ù…Ù„: ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø´Ø¨ÙƒØ© ÙˆØªØ­Ù„ÙŠÙ„ ÙƒÙ„ Ù…Ù†Ø·Ù‚Ø©
        # Ø§Ù„Ø¢Ù†: ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø®ØµØ§Ø¦Øµ Ø¹Ø§Ù…Ø©

        width = basic.dimensions.width
        height = basic.dimensions.height
        complexity = basic.content.estimated_complexity

        layout = {}

        # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¹Ù„ÙˆÙŠØ© (Ø¹Ø§Ø¯Ø© Ø³Ù…Ø§Ø¡ ÙÙŠ outdoorØŒ Ø³Ù‚Ù ÙÙŠ indoor)
        layout["top"] = SpatialHint(
            region="top",
            density=0.3,  # Ø¹Ø§Ø¯Ø© Ø£Ù‚Ù„ ÙƒØ«Ø§ÙØ©
            dominant_feature="sky_or_ceiling"
        )

        # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„ÙˆØ³Ø·Ù‰ (Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ)
        layout["center"] = SpatialHint(
            region="center",
            density=complexity,  # Ø£Ø¹Ù„Ù‰ ÙƒØ«Ø§ÙØ©
            dominant_feature="main_content"
        )

        # Ø§Ù„Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø³ÙÙ„ÙŠØ© (Ø¹Ø§Ø¯Ø© Ø£Ø±Ø¶/Ù‚Ø§Ø¹Ø¯Ø©)
        layout["bottom"] = SpatialHint(
            region="bottom",
            density=0.5,
            dominant_feature="ground_or_base"
        )

        return layout

    def _extract_contextual_clues(self,
                                  scene_type: SceneType,
                                  lighting: LightingCondition,
                                  time_hint: Optional[str],
                                  weather_hint: Optional[str],
                                  spatial_layout: Dict[str, SpatialHint]) -> List[str]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚Ø±Ø§Ø¦Ù† Ø³ÙŠØ§Ù‚ÙŠØ©"""
        clues = []

        # Ù‚Ø±Ø§Ø¦Ù† Ù…Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ø´Ù‡Ø¯
        if scene_type == SceneType.OUTDOOR:
            clues.append("Open environment, likely natural or urban setting")
        elif scene_type == SceneType.INDOOR:
            clues.append("Enclosed space, possibly building interior")
        elif scene_type == SceneType.WORKSPACE:
            clues.append("Work or study environment")
        elif scene_type == SceneType.SOCIAL:
            clues.append("Social gathering or event")

        # Ù‚Ø±Ø§Ø¦Ù† Ù…Ù† Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„ÙˆÙ‚Øª
        if time_hint:
            clues.append(f"Time of day appears to be {time_hint}")

        if weather_hint:
            clues.append(f"Weather conditions suggest {weather_hint}")

        # Ù‚Ø±Ø§Ø¦Ù† Ù…Ù† Ø§Ù„ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ù…ÙƒØ§Ù†ÙŠ
        center_density = spatial_layout.get("center", SpatialHint("center", 0.5, "unknown")).density
        if center_density > 0.7:
            clues.append("High activity or detail in central region")
        elif center_density < 0.3:
            clues.append("Minimal central content, possibly minimalist composition")

        return clues

    def _calculate_complexity(self, basic: 'ImageAnalysisResult') -> float:
        """Ø­Ø³Ø§Ø¨ ØªØ¹Ù‚ÙŠØ¯ Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        if not basic:
            return 0.5

        # Ø¯Ù…Ø¬ Ø¹Ø¯Ø© Ø¹ÙˆØ§Ù…Ù„
        edge_ratio = min(basic.content.edges_detected / (basic.dimensions.width * basic.dimensions.height), 1.0) if basic.dimensions.width * basic.dimensions.height > 0 else 0.5
        color_diversity = basic.colors.color_diversity
        content_complexity = basic.content.estimated_complexity

        # Ù…ØªÙˆØ³Ø· Ù…ÙˆØ²ÙˆÙ†
        complexity = (edge_ratio * 0.4 + color_diversity * 0.3 + content_complexity * 0.3)

        return min(complexity, 1.0)

    def _calculate_interpretability(self, context: SceneContext, complexity: float) -> float:
        """Ø­Ø³Ø§Ø¨ Ù…Ø¯Ù‰ Ø³Ù‡ÙˆÙ„Ø© ØªÙØ³ÙŠØ± Ø§Ù„Ù…Ø´Ù‡Ø¯"""
        # Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ø¨Ø³ÙŠØ·Ø© Ø£Ø³Ù‡Ù„ Ù„Ù„ØªÙØ³ÙŠØ±
        base_interpretability = 1.0 - (complexity * 0.5)

        # Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ© Ø£Ø³Ù‡Ù„ Ù„Ù„ØªÙØ³ÙŠØ±
        if context.scene_type != SceneType.UNKNOWN:
            base_interpretability += 0.2

        # ÙˆØ¬ÙˆØ¯ Ù‚Ø±Ø§Ø¦Ù† Ø³ÙŠØ§Ù‚ÙŠØ© ÙŠØ³Ù‡Ù„ Ø§Ù„ØªÙØ³ÙŠØ±
        clue_bonus = min(len(context.contextual_clues) * 0.05, 0.2)
        base_interpretability += clue_bonus

        return min(base_interpretability, 1.0)

    def _calculate_context_confidence(self,
                                     basic: 'ImageAnalysisResult',
                                     scene_type: SceneType,
                                     lighting: LightingCondition) -> float:
        """Ø­Ø³Ø§Ø¨ Ø«Ù‚Ø© ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚"""
        confidence = 0.5  # Ù‚ÙŠÙ…Ø© Ø£Ø³Ø§Ø³ÙŠØ©

        # Ù…Ø¤Ø´Ø±Ø§Øª ÙˆØ§Ø¶Ø­Ø© â†’ Ø«Ù‚Ø© Ø£Ø¹Ù„Ù‰
        if scene_type != SceneType.UNKNOWN:
            confidence += 0.2

        if lighting != LightingCondition.MIXED:
            confidence += 0.15

        # Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© ØªØ¤Ø«Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø«Ù‚Ø©
        if basic.dimensions.megapixels > 1.0:
            confidence += 0.1

        # ØªÙ†ÙˆØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙŠØ³Ø§Ø¹Ø¯ Ø¹Ù„Ù‰ Ø§Ù„ØªÙ…ÙŠÙŠØ²
        if basic.colors.color_diversity > 0.4:
            confidence += 0.05

        return min(confidence, 1.0)

    def _fallback_context(self) -> SceneContext:
        """Ø³ÙŠØ§Ù‚ Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø¹Ù†Ø¯ Ø¹Ø¯Ù… ØªÙˆÙØ± ImageAnalyzer"""
        return SceneContext(
            scene_type=SceneType.UNKNOWN,
            lighting_condition=LightingCondition.MIXED,
            time_of_day_hint=None,
            weather_hint=None,
            spatial_layout={},
            contextual_clues=["Basic analysis unavailable"],
            confidence=0.1
        )

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ"""
        return {
            "total_analyzed": self.total_analyzed,
            "scene_type_distribution": {
                scene_type.value: count
                for scene_type, count in self.scene_type_counts.items()
            },
            "image_analyzer_available": IMAGE_ANALYZER_AVAILABLE
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Usage Example
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("ğŸ” Scene Understanding Engine - Test")
    print("=" * 70)
    print()

    engine = SceneUnderstandingEngine()

    print(f"ImageAnalyzer Available: {engine.image_analyzer is not None}")
    print()

    # ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ:
    # result = engine.analyze_scene("path/to/image.jpg")
    # print(f"Scene Type: {result.scene_context.scene_type.value}")
    # print(f"Lighting: {result.scene_context.lighting_condition.value}")
    # print(f"Contextual Clues: {result.scene_context.contextual_clues}")

    print("=" * 70)
    print("âœ… Scene Understanding Engine initialized!")
    print("   Enhanced capabilities:")
    print("   - Scene type classification (indoor/outdoor/urban/nature/...)")
    print("   - Lighting condition analysis")
    print("   - Time of day inference")
    print("   - Weather hints from colors")
    print("   - Spatial layout analysis")
    print("   - Contextual clue extraction")
    print()
