"""
OCR Engine - Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ±
==========================================

ÙŠØ³ØªØ®Ø±Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ± Ø¨Ø¹Ø¯Ø© Ù„ØºØ§Øª (Ø¹Ø±Ø¨ÙŠØŒ Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØŒ Ø¥Ù„Ø®)

Addresses Q6 from Self-Audit (Computer Vision)

Author: Noogh AI Team
Date: 2025-11-10
Priority: HIGH
"""

from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime, timezone
from enum import Enum
import os
import re
from pathlib import Path


class OCRLanguage(str, Enum):
    """Ø§Ù„Ù„ØºØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©"""
    ARABIC = "ara"
    ENGLISH = "eng"
    FRENCH = "fra"
    SPANISH = "spa"
    AUTO = "auto"


class OCRConfidence(str, Enum):
    """Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ù†ØªÙŠØ¬Ø©"""
    HIGH = "high"  # > 90%
    MEDIUM = "medium"  # 70-90%
    LOW = "low"  # 50-70%
    VERY_LOW = "very_low"  # < 50%


@dataclass
class TextRegion:
    """Ù…Ù†Ø·Ù‚Ø© Ù†Øµ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©"""
    text: str
    bbox: Tuple[int, int, int, int]  # (x, y, width, height)
    confidence: float  # 0.0-1.0
    language: Optional[str] = None


@dataclass
class OCRResult:
    """Ù†ØªÙŠØ¬Ø© OCR"""
    full_text: str
    regions: List[TextRegion]
    detected_languages: List[str]
    average_confidence: float
    confidence_level: OCRConfidence
    processing_time_ms: float
    timestamp: datetime

    def to_dict(self) -> Dict[str, Any]:
        return {
            "full_text": self.full_text,
            "regions": [
                {
                    "text": r.text,
                    "bbox": r.bbox,
                    "confidence": r.confidence,
                    "language": r.language
                }
                for r in self.regions
            ],
            "detected_languages": self.detected_languages,
            "average_confidence": self.average_confidence,
            "confidence_level": self.confidence_level.value,
            "processing_time_ms": self.processing_time_ms
        }


class OCREngine:
    """
    Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„ØµÙˆØ±

    ÙŠØ¯Ø¹Ù…:
    1. Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©
    2. ÙƒØ´Ù Ø§Ù„Ù„ØºØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    3. Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù†ØµÙˆØµ
    4. Ù‚ÙŠØ§Ø³ Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
    """

    def __init__(self, default_language: OCRLanguage = OCRLanguage.AUTO):
        """
        Args:
            default_language: Ø§Ù„Ù„ØºØ© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        """
        self.default_language = default_language
        self.supported_languages = [
            OCRLanguage.ARABIC,
            OCRLanguage.ENGLISH,
            OCRLanguage.FRENCH,
            OCRLanguage.SPANISH
        ]

        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ tesseract Ø¥Ù† ÙˆØ¬Ø¯
        self.tesseract_available = self._check_tesseract()

        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.total_processed = 0
        self.total_errors = 0
        self.processing_history: List[OCRResult] = []

    def _check_tesseract(self) -> bool:
        """ÙØ­Øµ ØªÙˆÙØ± tesseract OCR"""
        try:
            import pytesseract
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ù€ tesseract
            pytesseract.get_tesseract_version()
            return True
        except Exception as e:
            # Error caught: {e}
            return False

    def extract_text(self,
                    image_path: str,
                    language: OCRLanguage = None,
                    detect_regions: bool = True) -> OCRResult:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† ØµÙˆØ±Ø©

        Args:
            image_path: Ù…Ø³Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©
            language: Ø§Ù„Ù„ØºØ© (None = Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ)
            detect_regions: ÙƒØ´Ù Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„Ù…Ù†ÙØµÙ„Ø©

        Returns:
            OCRResult
        """
        start_time = datetime.now(timezone.utc)

        if language is None:
            language = self.default_language

        # ÙØ­Øµ ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image not found: {image_path}")

        try:
            if self.tesseract_available:
                result = self._extract_with_tesseract(image_path, language, detect_regions)
            else:
                # Fallback: Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· (Ù„Ù„ØªØ·ÙˆÙŠØ±/Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±)
                result = self._extract_basic(image_path, language)

            # Ø­Ø³Ø§Ø¨ ÙˆÙ‚Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            processing_time = (datetime.now(timezone.utc) - start_time).total_seconds() * 1000

            result.processing_time_ms = processing_time
            result.timestamp = start_time

            self.total_processed += 1
            self.processing_history.append(result)

            return result

        except Exception as e:
            self.total_errors += 1
            raise RuntimeError(f"OCR extraction failed: {str(e)}")

    def _extract_with_tesseract(self,
                                image_path: str,
                                language: OCRLanguage,
                                detect_regions: bool) -> OCRResult:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Tesseract OCR"""
        try:
            import pytesseract
            from PIL import Image
        except ImportError:
            raise ImportError("pytesseract or PIL not installed. Install with: pip install pytesseract pillow")

        # ÙØªØ­ Ø§Ù„ØµÙˆØ±Ø©
        image = Image.open(image_path)

        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ©
        if language == OCRLanguage.AUTO:
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ÙƒØ´Ù Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
            lang_code = "ara+eng"  # Ø¯Ø¹Ù… Ø¹Ø±Ø¨ÙŠ ÙˆØ¥Ù†Ø¬Ù„ÙŠØ²ÙŠ Ù…Ø¹Ø§Ù‹
        else:
            lang_code = language.value

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ø§Ù„ÙƒØ§Ù…Ù„
        full_text = pytesseract.image_to_string(image, lang=lang_code)

        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø¥Ù† Ø·ÙÙ„Ø¨
        regions = []
        detected_languages = set()

        if detect_regions:
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØµÙŠÙ„ÙŠØ©
            data = pytesseract.image_to_data(image, lang=lang_code, output_type=pytesseract.Output.DICT)

            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚
            n_boxes = len(data['text'])
            for i in range(n_boxes):
                text = data['text'][i].strip()
                if text:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ù†ØµÙˆØµ Ø§Ù„ÙØ§Ø±ØºØ©
                    conf = float(data['conf'][i]) / 100.0  # ØªØ­ÙˆÙŠÙ„ Ù„Ù†Ø·Ø§Ù‚ 0-1

                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ©
                    detected_lang = self._detect_language_simple(text)
                    detected_languages.add(detected_lang)

                    region = TextRegion(
                        text=text,
                        bbox=(
                            data['left'][i],
                            data['top'][i],
                            data['width'][i],
                            data['height'][i]
                        ),
                        confidence=conf,
                        language=detected_lang
                    )
                    regions.append(region)

        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø© Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©
        if regions:
            avg_confidence = sum(r.confidence for r in regions) / len(regions)
        else:
            # fallback: Ù†Øµ ÙˆØ§Ø­Ø¯ Ù…Ø¹ Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©
            avg_confidence = 0.7
            detected_languages.add("unknown")

        confidence_level = self._classify_confidence(avg_confidence)

        return OCRResult(
            full_text=full_text.strip(),
            regions=regions,
            detected_languages=list(detected_languages),
            average_confidence=avg_confidence,
            confidence_level=confidence_level,
            processing_time_ms=0.0,  # Ø³ÙŠØªÙ… ØªØ­Ø¯ÙŠØ«Ù‡Ø§
            timestamp=datetime.now(timezone.utc)
        )

    def _extract_basic(self, image_path: str, language: OCRLanguage) -> OCRResult:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· (Ù„Ù„Ø­Ø§Ù„Ø§Øª Ø§Ù„ØªÙŠ Ù„Ø§ ÙŠØªÙˆÙØ± ÙÙŠÙ‡Ø§ tesseract)

        Ù…Ù„Ø­ÙˆØ¸Ø©: Ù‡Ø°Ø§ placeholder Ù„Ù„ØªØ·ÙˆÙŠØ± - ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙŠÙÙØ¶Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… tesseract
        """
        # Ù…Ø­Ø§ÙƒØ§Ø© Ù†ØªÙŠØ¬Ø© OCR Ø¨Ø³ÙŠØ·Ø©
        dummy_text = f"[OCR Placeholder: Image at {image_path}]"

        return OCRResult(
            full_text=dummy_text,
            regions=[
                TextRegion(
                    text=dummy_text,
                    bbox=(0, 0, 100, 50),
                    confidence=0.5,
                    language=language.value if language != OCRLanguage.AUTO else "eng"
                )
            ],
            detected_languages=["eng"],
            average_confidence=0.5,
            confidence_level=OCRConfidence.LOW,
            processing_time_ms=0.0,
            timestamp=datetime.now(timezone.utc)
        )

    def _detect_language_simple(self, text: str) -> str:
        """ÙƒØ´Ù Ø§Ù„Ù„ØºØ© Ø¨Ø´ÙƒÙ„ Ø¨Ø³ÙŠØ·"""
        # ÙØ­Øµ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
        arabic_chars = re.findall(r'[\u0600-\u06FF]', text)
        if len(arabic_chars) > len(text) * 0.3:  # Ø£ÙƒØ«Ø± Ù…Ù† 30% Ø£Ø­Ø±Ù Ø¹Ø±Ø¨ÙŠØ©
            return "ara"

        # ÙØ­Øµ Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„Ù„Ø§ØªÙŠÙ†ÙŠØ©
        latin_chars = re.findall(r'[a-zA-Z]', text)
        if len(latin_chars) > len(text) * 0.5:
            return "eng"

        return "unknown"

    def _classify_confidence(self, confidence: float) -> OCRConfidence:
        """ØªØµÙ†ÙŠÙ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
        if confidence >= 0.9:
            return OCRConfidence.HIGH
        elif confidence >= 0.7:
            return OCRConfidence.MEDIUM
        elif confidence >= 0.5:
            return OCRConfidence.LOW
        else:
            return OCRConfidence.VERY_LOW

    def extract_text_from_pdf(self, pdf_path: str, page_number: int = 0) -> OCRResult:
        """
        Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† ØµÙØ­Ø© PDF

        Args:
            pdf_path: Ù…Ø³Ø§Ø± Ù…Ù„Ù PDF
            page_number: Ø±Ù‚Ù… Ø§Ù„ØµÙØ­Ø© (0 = Ø§Ù„Ø£ÙˆÙ„Ù‰)
        """
        try:
            from pdf2image import convert_from_path
            import tempfile
        except ImportError:
            raise ImportError("pdf2image not installed. Install with: pip install pdf2image")

        # ØªØ­ÙˆÙŠÙ„ ØµÙØ­Ø© PDF Ù„ØµÙˆØ±Ø©
        with tempfile.TemporaryDirectory() as tmp_dir:
            images = convert_from_path(
                pdf_path,
                first_page=page_number + 1,
                last_page=page_number + 1,
                output_folder=tmp_dir
            )

            if not images:
                raise ValueError("Could not convert PDF page to image")

            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¤Ù‚ØªØ§Ù‹
            temp_image_path = os.path.join(tmp_dir, "temp_page.png")
            images[0].save(temp_image_path)

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
            return self.extract_text(temp_image_path)

    def get_statistics(self) -> Dict[str, Any]:
        """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ"""
        if self.total_processed == 0:
            return {
                "status": "no_data",
                "tesseract_available": self.tesseract_available
            }

        avg_confidence = sum(r.average_confidence for r in self.processing_history) / len(self.processing_history)
        avg_time = sum(r.processing_time_ms for r in self.processing_history) / len(self.processing_history)

        return {
            "total_processed": self.total_processed,
            "total_errors": self.total_errors,
            "success_rate": ((self.total_processed - self.total_errors) / self.total_processed) * 100,
            "average_confidence": avg_confidence,
            "average_processing_time_ms": avg_time,
            "tesseract_available": self.tesseract_available,
            "supported_languages": [lang.value for lang in self.supported_languages]
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# Usage Example
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

if __name__ == "__main__":
    print("ğŸ“· OCR Engine - Test")
    print("=" * 70)

    engine = OCREngine(default_language=OCRLanguage.AUTO)

    print(f"Tesseract available: {engine.tesseract_available}")
    print(f"Supported languages: {[lang.value for lang in engine.supported_languages]}")
    print()

    # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ (Ø¨Ø¯ÙˆÙ† ØµÙˆØ±Ø© ÙØ¹Ù„ÙŠØ©)
    print("ğŸ“ Simulating OCR extraction...")

    # ÙÙŠ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ:
    # result = engine.extract_text("path/to/image.png", language=OCRLanguage.ARABIC)

    print("\n" + "=" * 70)
    print("ğŸ“Š Statistics:")
    stats = engine.get_statistics()
    for key, value in stats.items():
        print(f"  {key}: {value}")
    print()

    print("âœ… OCR Engine initialized successfully!")
    print("   To use: result = engine.extract_text('image.png')")
    print()
